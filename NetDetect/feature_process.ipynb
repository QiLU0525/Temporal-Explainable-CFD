{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.25.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib as plt\n",
    "import re\n",
    "import torch\n",
    "import jieba\n",
    "import collections\n",
    "pd.__version__\n",
    "# 主要针对所有上市公司的 financial ratios、nonfinancial ratios、Linguistic features(MDA analysis)的分析"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预处理财务欺诈数据，从国泰安下载和处理财务违规数据:公司研究系列-> 审计信息-> 违规信息-> 上市公司财务违规表，1265条，2020/1/1 ~ 2022/12/31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weigui = pd.read_excel('../data/上市公司财务违规表/AR_FINVIOLATION_raw.xlsx',encoding=\"utf-8\")\n",
    "weigui.drop([0,1],axis=0,inplace=True)\n",
    "# 把违规的时间（ViolationYear）处理成 list 存在原处\n",
    "for i in weigui.index:\n",
    "    vio_years = weigui.loc[i,'ViolationYear']\n",
    "    if vio_years is np.nan:\n",
    "        continue\n",
    "    if ';' in vio_years:\n",
    "        vio_years =  sorted(set(vio_years.split(';')) - set(['N/A','']))\n",
    "    else: # '用,分隔'\n",
    "        vio_years =  sorted(set(vio_years.split(',')) - set(['N/A','']))\n",
    "    weigui.loc[i,'ViolationYear'] = json.dumps([int(i) for i in vio_years])\n",
    "\n",
    "# 把‘Activity’列删除，因为里面有一些换行符\n",
    "weigui = weigui.drop(['Law','Activity'], axis=1)\n",
    "weigui.to_csv('../data/上市公司财务违规表/AR_FINVIOLATION.csv',encoding='gb18030',index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2023年5月24日，杜老师在改初稿(Section 5.1 -> Table 2)时，让把最初的违规公司限定在2003年到2021年，因此生成一个 AR_FINVIOLATION_since2003 初始文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weigui = pd.read_csv('../data/上市公司财务违规表/AR_FINVIOLATION.csv',encoding='gb18030')\n",
    "\n",
    "drop_before_2003 = []\n",
    "for i in weigui.index:\n",
    "    try:\n",
    "        vio_years = json.loads(weigui.loc[i,'ViolationYear'])\n",
    "    except:\n",
    "        continue\n",
    "    vio_years = [j for j in vio_years if j >= 2003]\n",
    "    if vio_years == []:\n",
    "        drop_before_2003.append(i)\n",
    "    else:\n",
    "        weigui.loc[i,'ViolationYear'] = json.dumps(vio_years)\n",
    "\n",
    "weigui.drop(drop_before_2003,axis=0,inplace=True)\n",
    "weigui.to_csv('../data/上市公司财务违规表/AR_FINVIOLATION_since2003.csv',encoding='gb18030',index=None)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预处理财务重述数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RestatementObject = {1:'年报', 2:'中报', 3:'季报', 4:'三季报', 5:'审计报告', 6:'财务报告'}\n",
    "RestatementType = {1: '收入确认', 2: '成本计价', 3: '费用计价', 4: '资产=存货计价', 5: '企业并购', 6: '分立', 7: '证券相关', 8: '重分类问题', 9: '关联交易', 10: '会计政策变更', 11: '股票拆分', 12: '股票红利', 13: '其他'}\n",
    "ReasonDescription = {1: '企业内部统计错误', 2: '法律或监管要求', 3: '媒体曝光或者是监管机构披露', 4: '审计机构统计错误', 5: '其他', 9: '其他', np.nan:'', 0:''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restate = pd.read_excel('../data/财务重述情况表/AR_FINRESTAT_raw.xlsx')\n",
    "restate.drop([0,1],axis=0,inplace=True)\n",
    "for i in restate.index:\n",
    "    restate.loc[i,'RestatementYear'] = int(restate.loc[i,'RestatementYear'].split('-')[0])\n",
    "    restate.loc[i,'RestatementObject'] = RestatementObject[restate.loc[i,'RestatementObject']]\n",
    "    restate.loc[i,'RestatementType'] = RestatementType[restate.loc[i,'RestatementType']]\n",
    "    restate.loc[i,'ReasonDescription'] = ReasonDescription[restate.loc[i,'ReasonDescription']]\n",
    "restate.to_csv('../data/财务重述情况表/AR_FINRESTAT.csv',encoding='gb18030',index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 处理 industry 和 financial ratios\n",
    "basic_info (financial ratios) 亟待更新，因为里面的财务指标只到2021年，22年的财务指标要等23年4月30日全部上市公司都披露财报以后才行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_dict ={\n",
    "    # 这四个是CG_CO里没有的\n",
    "    '金属制品、机械和设备修理业':'工业',\n",
    "    '其他服务业':'公用事业',\n",
    "    '居民服务业':'公用事业',\n",
    "    '管道运输业':'公用事业'\n",
    "}\n",
    "\n",
    "CG_CO= pd.read_csv('../data/行业_公司基本情况文件/CG_Co.csv',encoding='utf-8')\n",
    "for i in range(CG_CO.shape[0]):\n",
    "    key = CG_CO.loc[i,'Nnindnme']\n",
    "    value = CG_CO.loc[i,'Indnme']\n",
    "    industry_dict[key] = value\n",
    "\n",
    "# 会计信息质量->财务报告信息，包括财务指标、行业、公司规模\n",
    "# 表格预处理，包括年份的提取，然后行业的进一步分类\n",
    "basic_info = pd.read_excel('../data/会计信息质量-财务指标/AIQ_LCFinIndexY_raw.xlsx',encoding=\"gbk\")\n",
    "basic_info = basic_info.drop(index=[0,1],axis=0)\n",
    "basic_info = basic_info.reset_index(drop = True)\n",
    "\n",
    "# 对行业做一个更上层的归类\n",
    "basic_info['Industry'] = [industry_dict[i] for i in basic_info['IndustryName']]\n",
    "\n",
    "time = basic_info['EndDate']\n",
    "years = []\n",
    "for t in time:\n",
    "    years.append(t.split('-')[0])\n",
    "basic_info['EndDate'] = years\n",
    "\n",
    "# 中文编码的大小：gbk<gb2312<gb18030，一般情况下，gb18030编码都能解析gbk不能解析的编码信息。\n",
    "basic_info.to_excel('../data/会计信息质量-财务指标/AIQ_LCFinIndexY.xlsx',encoding='gb18030',index=None)\n",
    "# 不存为csv文件是因为csv文件会把11次方以上的数值后面的小数抹去"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 在 AIQ_LCFinIndexY.xlsx 上手动计算计算12个欺诈相关的财务指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>ShortName</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>AccountsReceivable</th>\n",
       "      <th>TotalCurrentAssets</th>\n",
       "      <th>Inventory</th>\n",
       "      <th>FixedAssets</th>\n",
       "      <th>TotalAssets</th>\n",
       "      <th>TotalCurrentliabilities</th>\n",
       "      <th>TotalLiabilities</th>\n",
       "      <th>...</th>\n",
       "      <th>IG</th>\n",
       "      <th>lev</th>\n",
       "      <th>LEV</th>\n",
       "      <th>OPM</th>\n",
       "      <th>rg</th>\n",
       "      <th>RG</th>\n",
       "      <th>sg</th>\n",
       "      <th>SG</th>\n",
       "      <th>sgee</th>\n",
       "      <th>SGEE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>深发展A</td>\n",
       "      <td>2000</td>\n",
       "      <td>-3.960032e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.587091e+09</td>\n",
       "      <td>6.722750e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.248862e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.929510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.960032e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>深发展A</td>\n",
       "      <td>2001</td>\n",
       "      <td>1.120290e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.763257e+09</td>\n",
       "      <td>1.201270e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.164993e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.969801</td>\n",
       "      <td>1.043347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.120290e+07</td>\n",
       "      <td>-0.028290</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>深发展A</td>\n",
       "      <td>2002</td>\n",
       "      <td>-7.627110e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.380640e+09</td>\n",
       "      <td>1.661664e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.623984e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.977324</td>\n",
       "      <td>1.007757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.627110e+08</td>\n",
       "      <td>-68.081553</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>深发展A</td>\n",
       "      <td>2003</td>\n",
       "      <td>-8.331532e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.388062e+09</td>\n",
       "      <td>1.928510e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.888859e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.979440</td>\n",
       "      <td>1.002165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.331532e+08</td>\n",
       "      <td>1.092358</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>深发展A</td>\n",
       "      <td>2004</td>\n",
       "      <td>-8.742457e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.243569e+09</td>\n",
       "      <td>2.042864e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.996018e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.977068</td>\n",
       "      <td>0.997579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.742457e+08</td>\n",
       "      <td>1.049322</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52569</td>\n",
       "      <td>900957</td>\n",
       "      <td>凌云B股</td>\n",
       "      <td>2017</td>\n",
       "      <td>8.886504e+07</td>\n",
       "      <td>1.975161e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.383558e+08</td>\n",
       "      <td>1.019428e+09</td>\n",
       "      <td>1.025854e+08</td>\n",
       "      <td>5.955854e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.584235</td>\n",
       "      <td>0.882582</td>\n",
       "      <td>0.305931</td>\n",
       "      <td>8.886504e+07</td>\n",
       "      <td>0.659136</td>\n",
       "      <td>9.811317e+07</td>\n",
       "      <td>1.216833</td>\n",
       "      <td>0.476506</td>\n",
       "      <td>0.735033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52570</td>\n",
       "      <td>900957</td>\n",
       "      <td>凌云B股</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.421202e+08</td>\n",
       "      <td>2.029610e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.037777e+08</td>\n",
       "      <td>1.007002e+09</td>\n",
       "      <td>9.661402e+07</td>\n",
       "      <td>5.554740e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551612</td>\n",
       "      <td>0.944161</td>\n",
       "      <td>0.260902</td>\n",
       "      <td>1.421202e+08</td>\n",
       "      <td>1.599281</td>\n",
       "      <td>1.061131e+08</td>\n",
       "      <td>1.081537</td>\n",
       "      <td>0.387669</td>\n",
       "      <td>0.813566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52571</td>\n",
       "      <td>900957</td>\n",
       "      <td>凌云B股</td>\n",
       "      <td>2019</td>\n",
       "      <td>1.779797e+08</td>\n",
       "      <td>2.318127e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.723017e+08</td>\n",
       "      <td>1.017715e+09</td>\n",
       "      <td>1.179856e+08</td>\n",
       "      <td>5.408456e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.531432</td>\n",
       "      <td>0.963416</td>\n",
       "      <td>0.241292</td>\n",
       "      <td>1.779797e+08</td>\n",
       "      <td>1.252318</td>\n",
       "      <td>1.050223e+08</td>\n",
       "      <td>0.989721</td>\n",
       "      <td>0.396076</td>\n",
       "      <td>1.021687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52572</td>\n",
       "      <td>900957</td>\n",
       "      <td>凌云B股</td>\n",
       "      <td>2020</td>\n",
       "      <td>2.077017e+08</td>\n",
       "      <td>2.468748e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.380555e+08</td>\n",
       "      <td>1.008562e+09</td>\n",
       "      <td>8.253442e+07</td>\n",
       "      <td>5.098344e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.505506</td>\n",
       "      <td>0.951216</td>\n",
       "      <td>0.219894</td>\n",
       "      <td>2.077017e+08</td>\n",
       "      <td>1.166997</td>\n",
       "      <td>9.940559e+07</td>\n",
       "      <td>0.946519</td>\n",
       "      <td>0.381757</td>\n",
       "      <td>0.963848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52573</td>\n",
       "      <td>900957</td>\n",
       "      <td>凌云B股</td>\n",
       "      <td>2021</td>\n",
       "      <td>2.658989e+08</td>\n",
       "      <td>2.862441e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.040129e+08</td>\n",
       "      <td>1.023537e+09</td>\n",
       "      <td>1.094620e+08</td>\n",
       "      <td>4.971634e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.485731</td>\n",
       "      <td>0.960880</td>\n",
       "      <td>0.244499</td>\n",
       "      <td>2.658989e+08</td>\n",
       "      <td>1.280196</td>\n",
       "      <td>1.130710e+08</td>\n",
       "      <td>1.137471</td>\n",
       "      <td>0.317993</td>\n",
       "      <td>0.832972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52574 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Symbol ShortName  EndDate  AccountsReceivable  TotalCurrentAssets  \\\n",
       "0           1      深发展A     2000       -3.960032e+08                 NaN   \n",
       "1           1      深发展A     2001        1.120290e+07                 NaN   \n",
       "2           1      深发展A     2002       -7.627110e+08                 NaN   \n",
       "3           1      深发展A     2003       -8.331532e+08                 NaN   \n",
       "4           1      深发展A     2004       -8.742457e+08                 NaN   \n",
       "...       ...       ...      ...                 ...                 ...   \n",
       "52569  900957      凌云B股     2017        8.886504e+07        1.975161e+08   \n",
       "52570  900957      凌云B股     2018        1.421202e+08        2.029610e+08   \n",
       "52571  900957      凌云B股     2019        1.779797e+08        2.318127e+08   \n",
       "52572  900957      凌云B股     2020        2.077017e+08        2.468748e+08   \n",
       "52573  900957      凌云B股     2021        2.658989e+08        2.862441e+08   \n",
       "\n",
       "       Inventory   FixedAssets   TotalAssets  TotalCurrentliabilities  \\\n",
       "0            NaN  1.587091e+09  6.722750e+10                      NaN   \n",
       "1            NaN  1.763257e+09  1.201270e+11                      NaN   \n",
       "2            NaN  2.380640e+09  1.661664e+11                      NaN   \n",
       "3            NaN  2.388062e+09  1.928510e+11                      NaN   \n",
       "4            NaN  3.243569e+09  2.042864e+11                      NaN   \n",
       "...          ...           ...           ...                      ...   \n",
       "52569        NaN  5.383558e+08  1.019428e+09             1.025854e+08   \n",
       "52570        NaN  5.037777e+08  1.007002e+09             9.661402e+07   \n",
       "52571        NaN  4.723017e+08  1.017715e+09             1.179856e+08   \n",
       "52572        NaN  4.380555e+08  1.008562e+09             8.253442e+07   \n",
       "52573        NaN  4.040129e+08  1.023537e+09             1.094620e+08   \n",
       "\n",
       "       TotalLiabilities  ...  IG       lev       LEV       OPM            rg  \\\n",
       "0          6.248862e+10  ... NaN  0.929510       NaN       NaN -3.960032e+08   \n",
       "1          1.164993e+11  ... NaN  0.969801  1.043347       NaN  1.120290e+07   \n",
       "2          1.623984e+11  ... NaN  0.977324  1.007757       NaN -7.627110e+08   \n",
       "3          1.888859e+11  ... NaN  0.979440  1.002165       NaN -8.331532e+08   \n",
       "4          1.996018e+11  ... NaN  0.977068  0.997579       NaN -8.742457e+08   \n",
       "...                 ...  ...  ..       ...       ...       ...           ...   \n",
       "52569      5.955854e+08  ... NaN  0.584235  0.882582  0.305931  8.886504e+07   \n",
       "52570      5.554740e+08  ... NaN  0.551612  0.944161  0.260902  1.421202e+08   \n",
       "52571      5.408456e+08  ... NaN  0.531432  0.963416  0.241292  1.779797e+08   \n",
       "52572      5.098344e+08  ... NaN  0.505506  0.951216  0.219894  2.077017e+08   \n",
       "52573      4.971634e+08  ... NaN  0.485731  0.960880  0.244499  2.658989e+08   \n",
       "\n",
       "              RG            sg        SG      sgee      SGEE  \n",
       "0            NaN  0.000000e+00       NaN       NaN       NaN  \n",
       "1      -0.028290  0.000000e+00       NaN       NaN       NaN  \n",
       "2     -68.081553  0.000000e+00       NaN       NaN       NaN  \n",
       "3       1.092358  0.000000e+00       NaN       NaN       NaN  \n",
       "4       1.049322  0.000000e+00       NaN       NaN       NaN  \n",
       "...          ...           ...       ...       ...       ...  \n",
       "52569   0.659136  9.811317e+07  1.216833  0.476506  0.735033  \n",
       "52570   1.599281  1.061131e+08  1.081537  0.387669  0.813566  \n",
       "52571   1.252318  1.050223e+08  0.989721  0.396076  1.021687  \n",
       "52572   1.166997  9.940559e+07  0.946519  0.381757  0.963848  \n",
       "52573   1.280196  1.130710e+08  1.137471  0.317993  0.832972  \n",
       "\n",
       "[52574 rows x 46 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_info = pd.read_excel('../data/会计信息质量-财务指标/AIQ_LCFinIndexY.xlsx',encoding='gb18030')\n",
    "basic_info\n",
    "# 总资产数据，所有公司都有"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取基于国泰安的12个财务指标，然后把每个公司已记录的第一年指标全设为 Nan\n",
    "finRatio = pd.read_excel('../data/会计信息质量-财务指标/AIQ_LCFinIndexY.xlsx',encoding='gb18030')\n",
    "# 把第一年的指标归零，因为第一年算出来的指标是错的，用的是当前公司的第一年除以上面一家公司的最后一年。\n",
    "\n",
    "pre_firm = ''\n",
    "for i in range(finRatio.shape[0]):\n",
    "    firm = finRatio.loc[i,'Symbol']\n",
    "    if firm != pre_firm:\n",
    "        # 把所有的 指标设为 nan\n",
    "        finRatio.iloc[i,25:] = np.nan\n",
    "    pre_firm = firm\n",
    "\n",
    "used_columns = ['Symbol', 'ShortName', 'EndDate', 'TotalAssets', 'OperatingRevenue', 'Industry', 'AQI', 'AT', 'CFED', 'DSIR', 'DEPI', 'GMI', 'IG', 'LEV', 'OPM', 'RG', 'SG', 'SGEE']\n",
    "finRatio.loc[:,used_columns].to_excel('../data/会计信息质量-财务指标/AIQ_LCFinIndexY_s1.xlsx',index=None,encoding='gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "finRatio = pd.read_excel('../data/会计信息质量-财务指标/AIQ_LCFinIndexY_s1.xlsx', encoding='gb18030')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一阶段筛选：\\\n",
    "把全为nan和2000、2001、2022年的行删掉\\\n",
    "2002年的数据先保留一下，在算 R1-P1、R2-P2...的时候有用\\\n",
    "生成 AIQ_LCFinIndexY_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共有4968行的数据总资产、行业和12个指标全为空\n",
      "共有1081行的数据在2002年以前，且也不是2022年以后\n"
     ]
    }
   ],
   "source": [
    "finRatio = pd.read_excel('../data/会计信息质量-财务指标/AIQ_LCFinIndexY_s1.xlsx', encoding='gb18030')\n",
    "\n",
    "drop_index_1 = []\n",
    "drop_index_2 = []\n",
    "# 先把 含有 Nan 的行删掉。\n",
    "for i in range(finRatio.shape[0]):\n",
    "    if finRatio.loc[i,:].isnull().tolist().count(True)>=11:\n",
    "        drop_index_1.append(i)\n",
    "\n",
    "    elif int(finRatio.loc[i,'EndDate']) in [2000, 2001, 2022]:\n",
    "        # 2002 年的数据先不删，在 算 R1-P1、R2-P2...的时候有用\n",
    "        drop_index_2.append(i)\n",
    "\n",
    "print('共有%d行的数据总资产、行业和12个指标全为空' % len(drop_index_1))\n",
    "print('共有%d行的数据在2002年以前，且也不是2022年以后' % len(drop_index_2))\n",
    "\n",
    "finRatio = finRatio.drop(drop_index_1 + drop_index_2, axis=0)\n",
    "finRatio = finRatio.set_index(['Symbol'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一阶段结束后，将一些0值和空值补成1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_values(df):\n",
    "    # 可以补齐的一些指标\n",
    "    padding_cols = ['AQI', 'DSIR','DEPI', 'GMI', 'IG', 'LEV', 'RG', 'SG', 'SGEE']\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    if df.iloc[:,5:].isnull().sum().sum()/(df.shape[0] * (df.shape[1]-5)) < 0.1:\n",
    "        # 空值如果超过了 10%，就不用补了，之后直接把这家公司筛了\n",
    "        for col in padding_cols:\n",
    "            for i in range(df.shape[0]):\n",
    "                if df.loc[i, col]==0:\n",
    "                    if i+1==df.shape[0] or str(df.loc[i+1, col])== 'nan':\n",
    "                        # 值为0，在最后一行或者下一行是nan，则说明0值是由 nan/非零值 算出来的，这个时候应该把0改成1\n",
    "                        df.loc[i,col] = 1\n",
    "                elif str(df.loc[i, col]) == 'nan':\n",
    "                    df.loc[i,col] = 1\n",
    "    return df\n",
    "\n",
    "for symbol in sorted(set(finRatio.index)):\n",
    "    df = finRatio.loc[symbol,:]\n",
    "    if df.shape==(17,):\n",
    "        # 只有一行，不用补了\n",
    "        continue\n",
    "    # finRatio.loc[symbol,:] = padding_values(df)\n",
    "    # padding_cols = ['AQI', 'DSIR','DEPI', 'GMI', 'IG', 'LEV', 'RG', 'SG', 'SGEE']\n",
    "    padding_cols = [5,8,9,10,11,12,14,15,16]\n",
    "    # df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    if df.iloc[:,5:].isnull().sum().sum()/(df.shape[0] * (df.shape[1]-5)) < 0.1:\n",
    "        # 空值如果超过了 10%，就不用补了，之后直接把这家公司筛了\n",
    "        for col in padding_cols:\n",
    "            for i in range(df.shape[0]):\n",
    "                if df.iloc[i, col]==0:\n",
    "                    if i+1== df.shape[0] or str(df.iloc[i+1, col])== 'nan':\n",
    "                        # 值为0，在最后一行或者下一行是nan，则说明0值是由 nan/非零值 算出来的，这个时候应该把0改成1\n",
    "                        df.iloc[i,col] = 1\n",
    "                elif str(df.iloc[i, col]) == 'nan':\n",
    "                    df.iloc[i,col] = 1\n",
    "finRatio.to_excel('../data/会计信息质量-财务指标/AIQ_LCFinIndexY_padded.xlsx',encoding='gb18030')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二阶段筛选：在第一轮筛选过后，补齐了一些值，但还是有一些公司因为缺失值太多了，不适合补齐。第二轮筛选主要达到最后的文件中没有空值，包括去除一些金融公司和只有一年数据的公司"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始公司有4500家\n",
      "共有482家公司只有一年数据\n",
      "共有3899家公司不是金融公司\n",
      "共有3855家公司没有缺失指标\n"
     ]
    }
   ],
   "source": [
    "finRatio = pd.read_excel('../data/会计信息质量-财务指标/AIQ_LCFinIndexY_padded.xlsx',encoding='gb18030')\n",
    "# 把2002年的数据删了，因为2002年的数据只是用来后面计算Pi的。\n",
    "finRatio.drop(finRatio[finRatio.EndDate==2002].index, axis=0, inplace=True)\n",
    "finRatio = finRatio.set_index(['Symbol'])\n",
    "\n",
    "n_nonfin_corp = set()\n",
    "# n_no_weigui = set()\n",
    "n_only_one_year = set()\n",
    "n_no_missing_data = set()\n",
    "drop_firms = []\n",
    "print('初始公司有%s家' % len(set(finRatio.index)))\n",
    "\n",
    "for firm in sorted(set(finRatio.index)):\n",
    "    df = finRatio.loc[firm,:]\n",
    "    if df.shape==(17,):\n",
    "        # 只有一年的数据，也用不了\n",
    "        n_only_one_year.add(firm)\n",
    "        drop_firms.append(firm)\n",
    "    else:\n",
    "        ind = df.Industry.tolist() if type(df.Industry) is not str else df.Industry\n",
    "        if '金融' not in ind:\n",
    "            n_nonfin_corp.add(firm)\n",
    "            if df.isnull().sum().sum()==0:\n",
    "                # 判断指标缺失的公司\n",
    "                n_no_missing_data.add(firm)\n",
    "            else:\n",
    "                drop_firms.append(firm)\n",
    "        else:\n",
    "            drop_firms.append(firm)\n",
    "\n",
    "finRatio = finRatio.drop(drop_firms, axis=0)\n",
    "\n",
    "print('共有%d家公司只有一年数据' % len(n_only_one_year))\n",
    "print('共有%d家公司不是金融公司' % len(n_nonfin_corp))\n",
    "# print('共有%d家公司没有财务报表欺诈' % len(n_no_weigui))\n",
    "print('共有%d家公司没有缺失指标' % len(n_no_missing_data))\n",
    "finRatio.to_excel('../data/会计信息质量-财务指标/all_corp_fin_data.xlsx',encoding='gb18030')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算JMIS2018另外72个指标\\\n",
    "Ti (i = 1, 2, …, 12) is the averaged Ri of five largest firms (in terms of sales) in the same industry and year\\\n",
    "Ci (i = 1, 2, …, 12) is the averaged Ri of five similar firms (in terms of sales) in the same industry and year\\\n",
    "Pi (i = 1, 2, …, 12) is the same ratio of Ri in the previous year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luqi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "# 先计算 Industry-collaboration contextual features\n",
    "finRatio = pd.read_excel('../data/会计信息质量-财务指标/all_corp_fin_data.xlsx',encoding='gb18030')\n",
    "group_by_ind_year = finRatio.set_index(['Industry','EndDate'])\n",
    "# group_by_symbol_year 用来计算Ti，会涉及t-1年的数据，如果要算公司第一年的R1/P1，就会需要t-1年的数据，如2003年的R1/P1需要2002年的数据，而2002年的数据all_corp_fin_data里面没有，但AIQ_LCFinIndexY_padded里面有\n",
    "group_by_symbol_year = pd.read_excel('../data/会计信息质量-财务指标/AIQ_LCFinIndexY_padded.xlsx',encoding='gb18030').set_index(['Symbol','EndDate'])\n",
    "\n",
    "base_fin_name = ['AQI', 'AT', 'CFED', 'DSIR', 'DEPI', 'GMI', 'IG','LEV', 'OPM', 'RG', 'SG', 'SGEE']\n",
    "def generate_interval(index, total_size):\n",
    "    if total_size < 8:\n",
    "        return [i for i in range(total_size)]\n",
    "    elif index >= 3 and index + 2 < total_size:\n",
    "        return [index - 3, index - 2, index-1, index+1, index+2]\n",
    "    elif index + 2 >= total_size:\n",
    "        return [index - 5, index - 4, index - 3, index-2, index-1]\n",
    "    else: #  index < 3\n",
    "        return [index + 1, index + 2, index + 3, index+4, index+5]\n",
    "\n",
    "for i in range(finRatio.shape[0]):\n",
    "    stkcd, year = finRatio.loc[i, ['Symbol','EndDate']]\n",
    "    ind = group_by_symbol_year.loc[(stkcd, year), 'Industry']\n",
    "    # 按 sales 排序\n",
    "    batch_df = group_by_ind_year.loc[(ind, year), :].copy().sort_values(by=['OperatingRevenue'], ascending=False)\n",
    "    T = np.mean(\n",
    "            # ['AQI', 'AT', 'CFED', 'DSIR', 'DEPI', 'GMI', 'IG','LEV', 'OPM', 'RG', 'SG', 'SGEE']\n",
    "            batch_df.iloc[:5, [4,5,6,7,8,9,10,11,12,13,14,15]], axis=0\n",
    "        )\n",
    "    \n",
    "    index_in_batch = batch_df.Symbol.tolist().index(stkcd)\n",
    "    C = np.mean(\n",
    "        batch_df.iloc[generate_interval(index_in_batch, batch_df.shape[0]),[4,5,6,7,8,9,10,11,12,13,14,15]], axis = 0\n",
    "        )\n",
    "    \n",
    "    for j in range(len(base_fin_name)):\n",
    "        ratio_name = base_fin_name[j]\n",
    "        finRatio.loc[i, 'R%d-T%d' % (j+1,j+1) ] = finRatio.loc[i, ratio_name] - T[j]\n",
    "        finRatio.loc[i, 'R%d/T%d' % (j+1,j+1) ] = finRatio.loc[i, ratio_name] / T[j]\n",
    "\n",
    "    for j in range(len(base_fin_name)):\n",
    "        ratio_name = base_fin_name[j]\n",
    "        finRatio.loc[i, 'R%d-C%d' % (j+1,j+1) ] = finRatio.loc[i, ratio_name] - C[j]\n",
    "        finRatio.loc[i, 'R%d/C%d' % (j+1,j+1) ] = finRatio.loc[i, ratio_name] / C[j]\n",
    "\n",
    "    \n",
    "    for j in range(len(base_fin_name)):\n",
    "        try:\n",
    "            # 2002年的数据用来计算2003年的R%d-P%d，算完以后删除2002年\n",
    "            ratio_name = base_fin_name[j]\n",
    "            finRatio.loc[i, 'R%d-P%d' % (j+1,j+1) ] = finRatio.loc[i, ratio_name] - group_by_symbol_year.loc[(stkcd, year-1), ratio_name]\n",
    "            finRatio.loc[i, 'R%d/P%d' % (j+1,j+1) ] = finRatio.loc[i, ratio_name] / group_by_symbol_year.loc[(stkcd, year-1), ratio_name]\n",
    "        except:\n",
    "            # 说明没有t-1年的数据，暂时空着\n",
    "            continue\n",
    "\n",
    "finRatio.to_excel('../data/会计信息质量-财务指标/findata_84r.xlsx',encoding='gb18030',index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有些公司-年份的72个指标中还是存在一些空值，需要补齐一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luqi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/luqi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/Users/luqi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/Users/luqi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/luqi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/luqi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/luqi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/luqi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "finRatio = pd.read_excel('../data/会计信息质量-财务指标/findata_84r.xlsx',encoding='gb18030')\n",
    "for i in range(12):\n",
    "    # 识别 null 值，并用0或1补上\n",
    "    finRatio['R%d-C%d' % (i+1, i+1)][finRatio['R%d-C%d' % (i+1, i+1)].isnull()==True] = 0\n",
    "    finRatio['R%d/C%d' % (i+1, i+1)][finRatio['R%d/C%d' % (i+1, i+1)].isnull()==True] = 1\n",
    "\n",
    "    finRatio['R%d-P%d' % (i+1, i+1)][finRatio['R%d-P%d' % (i+1, i+1)].isnull()==True] = 0\n",
    "    finRatio['R%d/P%d' % (i+1, i+1)][finRatio['R%d/P%d' % (i+1, i+1)].isnull()==True] = 1\n",
    "\n",
    "    # 识别 inf，并用0或1补上\n",
    "    finRatio['R%d-C%d' % (i+1, i+1)][finRatio['R%d-C%d' % (i+1, i+1)]==np.inf] = 0\n",
    "    finRatio['R%d/C%d' % (i+1, i+1)][finRatio['R%d/C%d' % (i+1, i+1)]==np.inf] = 1\n",
    "\n",
    "    finRatio['R%d-P%d' % (i+1, i+1)][finRatio['R%d-P%d' % (i+1, i+1)]==np.inf] = 0\n",
    "    finRatio['R%d/P%d' % (i+1, i+1)][finRatio['R%d/P%d' % (i+1, i+1)]==np.inf] = 1\n",
    "    \n",
    "finRatio.to_excel('../data/会计信息质量-财务指标/findata_84r.xlsx',encoding='gb18030',index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后的最后，以公司为单位做标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "finRatio = pd.read_excel('../data/会计信息质量-财务指标/findata_84r.xlsx',encoding='gb18030')\n",
    "\n",
    "# temp = pd.DataFrame(columns=finRatio.columns,dtype=object)\n",
    "# temp.to_csv('会计信息质量-财务指标/findata_normlized.csv', encoding='gb18030',index=None)\n",
    "\n",
    "finRatio.set_index('Symbol', inplace=True)\n",
    "BN = torch.nn.BatchNorm1d(84, eps=1e-4)\n",
    "for i in sorted(set(finRatio.index)):\n",
    "    df = finRatio.loc[i,:]\n",
    "    temp = df.copy(deep=True)\n",
    "    normed_value = BN(torch.from_numpy(df.iloc[:,5:].values).float()).data.numpy()\n",
    "    temp.iloc[:,5:] = normed_value\n",
    "    finRatio.loc[i,:] = temp.values\n",
    "finRatio.to_excel('../data/会计信息质量-财务指标/findata_normlized.xlsx', encoding='gb18030')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 处理 non-financial ratios,处理完以后放在各自的文件夹里，并且生成一个总的文件 nonfin_data.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>**董事会特征Boardroom Characteristics**</u> (4 ratios)\\\n",
    "1.外部董事比例(The proportion of outside directors)\\\n",
    "2.董事会规模(The size of the board)\\\n",
    "3.董事会会议次数(the number of board meetings)\\\n",
    "4.董事会主席任期(the tenure of the chairman)\n",
    "\n",
    "<u>**所有人结构Ownership Structure**</u> (6 ratios)\\\n",
    "1.国家持股比例(The proportion of shares held by the state)\\\n",
    "2.法人持股比例(the proportion of shares held by legal entities)\\\n",
    "3.个人持股比例(the proportion of shares held by individuals)\\\n",
    "4.是否存在外资股东(the existence of foreign stockholders)\\\n",
    "5.单一第一大股东的持股比例(the proportion of shares held by the single largest stockholder)\\\n",
    "6.第二至第十大股东持股比例(the concentration of ownership in the hands of the second to tenth largest stockholders)\n",
    "\n",
    "<u>**审计Audit**</u> (6 ratios)\\\n",
    "审计质量(Auditor Quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 董事会规模、外部董事比例\n",
    "ratio_out_directors = pd.read_excel('../data/非财务指标/高管人数持股及薪酬情况表/CG_ManagerShareSalary_raw.xlsx')\n",
    "ratio_out_directors.drop([0,1],axis=0,inplace=True)\n",
    "\n",
    "ratio_out_directors.Enddate = [int(t.split('-')[0]) for t in ratio_out_directors.Enddate]\n",
    "ratio_out_directors.drop(['StatisticalCaliber'],axis=1,inplace=True)\n",
    "ratio_out_directors.drop_duplicates(subset=['Symbol','Enddate'],keep='last',inplace=True)\n",
    "ratio_out_directors.to_csv('../data/非财务指标/高管人数持股及薪酬情况表/CG_ManagerShareSalary.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 董事会会议次数\n",
    "'''\n",
    "A0101b: 董事会会议次数\n",
    "A0201b: 监事会会议次数\n",
    "A0301b: 股东大会召开次数\n",
    "'''\n",
    "board_meet = pd.read_excel('../data/非财务指标/三会基本信息文件/CG_Agm_raw.xlsx')\n",
    "board_meet.drop([0,1],axis=0,inplace=True)\n",
    "board_meet.Reptdt = [int(t.split('-')[0]) for t in board_meet.Reptdt]\n",
    "board_meet.to_csv('../data/非财务指标/三会基本信息文件/CG_Agm.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 董事会主席任期\n",
    "chairman_tenure = pd.read_excel('../data/非财务指标/董监高任职情况表/TMT_POSITION_raw.xlsx')\n",
    "chairman_tenure.drop([0,1],axis=0,inplace=True)\n",
    "chairman_tenure.Reptdt = [int(t.split('-')[0]) for t in chairman_tenure.Reptdt]\n",
    "chairman_tenure.drop_duplicates(subset=['Stkcd','Reptdt'],keep='last',inplace=True)\n",
    "chairman_tenure.to_csv('../data/非财务指标/董监高任职情况表/TMT_POSITION.csv',index=None,encoding='gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 国家持股、法人持股、个人持股、是否存在外资股东\n",
    "sharehold = pd.read_excel('../data/非财务指标/股本结构文件/CG_Capchg_raw.xlsx')\n",
    "sharehold.drop([0,1],axis=0,inplace=True)\n",
    "sharehold.Reptdt = [int(t.split('-')[0]) for t in sharehold.Reptdt]\n",
    "sharehold['nation_rate'] = [nat/total for total, nat in zip(sharehold.Nshrttl, sharehold.Nshrstt)]\n",
    "sharehold['legal_rate'] = [(in_legal+out_legal)/total for total, in_legal, out_legal in zip(sharehold.Nshrttl, sharehold.Nshrlpd, sharehold.Nshrlpf)]\n",
    "sharehold['personal_rate'] = [ind/total for total, ind in zip(sharehold.Nshrttl, sharehold.Nshrsms)]\n",
    "sharehold['is_abroad_exist'] = [1 if out_legal>0 else 0 for out_legal in sharehold.Nshrlpf]\n",
    "sharehold.to_csv('../data/非财务指标/股本结构文件/CG_Capchg.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一大股东持股比例、第二至第十大股东持股比例\n",
    "'''\n",
    "Shrcr1: 第一大股东持股比例\n",
    "Shrcr4: 前十大股东持股比例\n",
    "'''\n",
    "share_hold_rate = pd.read_excel('../data/非财务指标/十大股东股权集中文件/HLD_CR_raw.xlsx')\n",
    "share_hold_rate.drop([0,1],axis=0,inplace=True)\n",
    "share_hold_rate.Reptdt = [int(t.split('-')[0]) for t in share_hold_rate.Reptdt]\n",
    "share_hold_rate.drop_duplicates(subset=['Stkcd','Reptdt'],keep='last',inplace=True)\n",
    "share_hold_rate['1st_rate'] = share_hold_rate.Shrcr1\n",
    "share_hold_rate['2nd_10th_rate'] = [j-i for i,j in zip(share_hold_rate.Shrcr1, share_hold_rate.Shrcr4)]\n",
    "\n",
    "share_hold_rate.to_csv('../data/非财务指标/十大股东股权集中文件/HLD_CR.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 审计质量\n",
    "auditor_info = pd.read_excel('../data/非财务指标/中国百强会计师事务所排名表/AR_TOP100AFRANK.xlsx')\n",
    "auditor_info.drop([0,1],axis=0,inplace=True)\n",
    "auditor_info.set_index(['InstitutionID'],inplace=True)\n",
    "\n",
    "corp_audit_info = pd.read_excel('../data/非财务指标/上市公司审计机构列表/AR_LISTCOMPAUDIT_raw.xlsx')\n",
    "corp_audit_info.drop([0,1],axis=0,inplace=True)\n",
    "corp_audit_info.EndDate = [int(t.split('-')[0]) for t in corp_audit_info.EndDate]\n",
    "\n",
    "for i in corp_audit_info.index:\n",
    "    Ins_id = corp_audit_info.loc[i,'InstitutionID']\n",
    "    Ins_name = corp_audit_info.loc[i,'AccountingFirmName']\n",
    "    if Ins_id in set(auditor_info.index):\n",
    "        if corp_audit_info.loc[i,'TerritoryForeignIdentity']==1:\n",
    "            score_list = auditor_info.loc[Ins_id, 'CompositeScore']\n",
    "            corp_audit_info.loc[i,'AuditQuality'] = score_list.mean() if type(score_list)==pd.core.series.Series else score_list\n",
    "\n",
    "corp_audit_info.drop_duplicates(subset=['Symbol','EndDate'],keep='first',inplace=True)\n",
    "corp_audit_info[corp_audit_info.TerritoryForeignIdentity==1].to_csv('../data/非财务指标/上市公司审计机构列表/AR_LISTCOMPAUDIT.csv',encoding='gb18030',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "各个非财务指标处理结束，\n",
    "把所有 nonfinancial 指标的表拼接起来\n",
    "'''\n",
    "ratio_out_directors = pd.read_csv('../data/非财务指标/高管人数持股及薪酬情况表/CG_ManagerShareSalary.csv', encoding='gb18030')\n",
    "board_meet = pd.read_csv('../data/非财务指标/三会基本信息文件/CG_Agm.csv', encoding='gb18030')\n",
    "chairman_tenure = pd.read_csv('../data/非财务指标/董监高任职情况表/TMT_POSITION.csv', encoding='gb18030')\n",
    "sharehold = pd.read_csv('../data/非财务指标/股本结构文件/CG_Capchg.csv', encoding='gb18030')\n",
    "share_hold_rate = pd.read_csv('../data/非财务指标/十大股东股权集中文件/HLD_CR.csv', encoding='gb18030')\n",
    "corp_audit_info = pd.read_csv('../data/非财务指标/上市公司审计机构列表/AR_LISTCOMPAUDIT.csv',encoding='gb18030')\n",
    "\n",
    "ratio_out_directors.set_index(['Symbol','Enddate'],inplace=True)\n",
    "board_meet.set_index(['Stkcd','Reptdt'],inplace=True)\n",
    "chairman_tenure.set_index(['Stkcd','Reptdt'], inplace=True)\n",
    "sharehold.set_index(['Stkcd','Reptdt'],inplace=True)\n",
    "share_hold_rate.set_index(['Stkcd','Reptdt'],inplace=True)\n",
    "corp_audit_info.set_index(['Symbol','EndDate'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonfin_data = pd.concat([ratio_out_directors, \n",
    "            board_meet.A0101b, \n",
    "            chairman_tenure.Tenure, \n",
    "            sharehold[['nation_rate', 'legal_rate', 'personal_rate','is_abroad_exist']], \n",
    "            share_hold_rate[['1st_rate', '2nd_10th_rate']],\n",
    "            corp_audit_info.AuditQuality,\n",
    "        ],axis=1,ignore_index=False)\n",
    "\n",
    "nonfin_data.reset_index(drop=False,inplace=True)\n",
    "nonfin_data.rename(columns={'level_0':'Symbol','level_1':'year', 'A0101b':'board_meeting_num'},inplace=True)\n",
    "nonfin_data.to_csv('../data/非财务指标/nonfin_data_raw.csv', encoding='gb18030',index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nonfin_data文件构造完成，接下来要删除一些0值过多的行，补齐 nonfin_data 的空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonfin_data = pd.read_csv('../data/非财务指标/nonfin_data_raw.csv')\n",
    "\n",
    "# 22年空值有很多，把22年的行删了，2000、2001、2002年也一样\n",
    "nonfin_data.set_index(['year'],inplace=True)\n",
    "nonfin_data.drop([2000, 2001, 2002, 2022],inplace=True, axis=0)\n",
    "nonfin_data.reset_index(drop=False,inplace=True)\n",
    "nonfin_data.to_csv('../data/非财务指标/nonfin_data.csv',encoding='gb18030',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有11499行的指标几乎全是nan\n"
     ]
    }
   ],
   "source": [
    "nonfin_data = pd.read_csv('../data/非财务指标/nonfin_data.csv',encoding='gb18030')\n",
    "\n",
    "drop_index = []\n",
    "# 先把一些空值特别多(>9)的行删了\n",
    "for i in nonfin_data.index:\n",
    "    if nonfin_data.loc[i,:].isnull().sum() >= 8:\n",
    "        drop_index.append(i)\n",
    "print('有%d行的指标几乎全是nan' % len(drop_index))\n",
    "nonfin_data.drop(drop_index, inplace=True, axis=0)\n",
    "# nonfin_data = nonfin_data.set_index(['Symbol'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有541家公司只有一年数据，删掉\n",
      "补充完之后，还有85行数据有 nan 值，这些值因为上下文也是空的所以无法补充\n"
     ]
    }
   ],
   "source": [
    "n_only_one_year = []\n",
    "\n",
    "def padding_by_column(col):\n",
    "    for i in range(len(col)-2, -1, -1):\n",
    "        # 从倒数第二个开始，往前倒\n",
    "        if str(col[i]) == 'nan':\n",
    "            col[i] = col[i+1]\n",
    "    for i in range(1, len(col)):\n",
    "        # 再从正数第二个开始，往后倒\n",
    "        if str(col[i]) == 'nan':\n",
    "            col[i] = col[i-1]\n",
    "    return col        \n",
    "\n",
    "nonfin_by_firm = nonfin_data.set_index(['Symbol'],inplace=False)\n",
    "for firm in set(nonfin_by_firm.index):\n",
    "    df = nonfin_by_firm.loc[firm, :]\n",
    "    if df.shape == (12,):\n",
    "        # 只有一行，不满足时间序列要求，删掉\n",
    "        n_only_one_year.append(firm)\n",
    "        continue\n",
    "    # 先补 tenure\n",
    "    tenure = df.Tenure.copy().tolist()\n",
    "    for i in range(len(tenure)-2, -1, -1):\n",
    "        # 从倒数第二个开始，往前倒\n",
    "        if str(tenure[i]) == 'nan':\n",
    "            tenure[i] = tenure[i+1] - 12 if tenure[i+1] > 12 else np.nan\n",
    "    for i in range(1, len(tenure)):\n",
    "        # 再从正数第二个开始，往后倒\n",
    "        if str(tenure[i]) == 'nan':\n",
    "            tenure[i] = tenure[i-1] + 12\n",
    "    nonfin_by_firm.loc[firm, 'Tenure'] = tenure\n",
    "    # 再补别的\n",
    "    nonfin_by_firm.loc[firm, 'DirectorNumber'] = padding_by_column(df.DirectorNumber.copy().tolist())\n",
    "    nonfin_by_firm.loc[firm, 'IndependentDirectorNumber'] = padding_by_column(df.IndependentDirectorNumber.copy().tolist())\n",
    "    nonfin_by_firm.loc[firm, 'board_meeting_num'] = padding_by_column(df.board_meeting_num.copy().tolist())\n",
    "    nonfin_by_firm.loc[firm, 'nation_rate'] = padding_by_column(df.nation_rate.copy().tolist())\n",
    "    nonfin_by_firm.loc[firm, 'legal_rate'] = padding_by_column(df.legal_rate.copy().tolist())\n",
    "    nonfin_by_firm.loc[firm, 'personal_rate'] = padding_by_column(df.personal_rate.copy().tolist())\n",
    "    nonfin_by_firm.loc[firm, '1st_rate'] = padding_by_column(df[\"1st_rate\"].copy().tolist())\n",
    "    nonfin_by_firm.loc[firm, '2nd_10th_rate'] = padding_by_column(df[\"2nd_10th_rate\"].copy().tolist())\n",
    "    nonfin_by_firm.loc[firm, 'AuditQuality'] = padding_by_column(df.AuditQuality.copy().tolist())\n",
    "\n",
    "print('有%d家公司只有一年数据，删掉'%len(n_only_one_year))\n",
    "nonfin_by_firm.drop(n_only_one_year, inplace=True, axis=0)\n",
    "nonfin = nonfin_by_firm.reset_index(drop=False,inplace=False)\n",
    "'''\n",
    "补完以后，还有一些地方有空值，比如Tenure，AuditQuality，是因为公司所有年份的值都是空的，就不能根据上下两行的数据来补\n",
    "因此将有空值的行全删了，保证整个表格没有一处地方有空值\n",
    "'''\n",
    "drop_index = []\n",
    "for i in nonfin.index:\n",
    "    if nonfin.loc[i,:].isnull().sum() >0 :\n",
    "        drop_index.append(i)\n",
    "print('补充完之后，还有%d行数据有 nan 值，这些值因为上下文也是空的所以无法补充' % len(drop_index))\n",
    "nonfin.drop(drop_index, inplace=True, axis = 0)\n",
    "\n",
    "nonfin.to_csv('../data/非财务指标/nonfin_data_v2.csv',encoding='gb18030',index=None)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### nonfinancial ratios 的处理暂时结束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonfin = pd.read_csv('../data/非财务指标/nonfin_data_v2.csv',encoding='gb18030')\n",
    "\n",
    "# temp = pd.DataFrame(columns=finRatio.columns,dtype=object)\n",
    "# temp.to_csv('会计信息质量-财务指标/findata_normlized.csv', encoding='gb18030',index=None)\n",
    "\n",
    "nonfin.set_index('Symbol', inplace=True)\n",
    "BN = torch.nn.BatchNorm1d(11, eps=1e-4)\n",
    "normed_value = BN(torch.from_numpy(nonfin.iloc[:,1:].values).float()).data.numpy()\n",
    "\n",
    "nonfin.loc[:,1:] = normed_value\n",
    "'''for i in sorted(set(finRatio.index)):\n",
    "    df = nonfin.loc[i,:]\n",
    "    temp = df.copy(deep=True)\n",
    "    normed_value = BN(torch.from_numpy(df.iloc[:,5:].values).float()).data.numpy()\n",
    "    temp.iloc[:,5:] = normed_value\n",
    "    finRatio.loc[i,:] = temp.values'''\n",
    "nonfin.to_csv('../data/非财务指标/nonfin_normlized.csv', encoding='gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>year</th>\n",
       "      <th>DirectorNumber</th>\n",
       "      <th>IndependentDirectorNumber</th>\n",
       "      <th>board_meeting_num</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>nation_rate</th>\n",
       "      <th>legal_rate</th>\n",
       "      <th>personal_rate</th>\n",
       "      <th>is_abroad_exist</th>\n",
       "      <th>1st_rate</th>\n",
       "      <th>2nd_10th_rate</th>\n",
       "      <th>AuditQuality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.064441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0838</td>\n",
       "      <td>18.9276</td>\n",
       "      <td>59.944286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>0.274816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.8898</td>\n",
       "      <td>8.8375</td>\n",
       "      <td>59.944286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>0.274816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.8898</td>\n",
       "      <td>9.3922</td>\n",
       "      <td>59.944286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>0.274816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.8898</td>\n",
       "      <td>11.8932</td>\n",
       "      <td>59.944286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.231715</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.6963</td>\n",
       "      <td>14.3021</td>\n",
       "      <td>1019.076154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47958</td>\n",
       "      <td>900957</td>\n",
       "      <td>2017</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.472779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.6189</td>\n",
       "      <td>18.8200</td>\n",
       "      <td>728.642500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47959</td>\n",
       "      <td>900957</td>\n",
       "      <td>2018</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.472779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.6189</td>\n",
       "      <td>18.4098</td>\n",
       "      <td>728.642500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47960</td>\n",
       "      <td>900957</td>\n",
       "      <td>2019</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.472779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.6189</td>\n",
       "      <td>18.5604</td>\n",
       "      <td>728.642500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47961</td>\n",
       "      <td>900957</td>\n",
       "      <td>2020</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.472779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.6189</td>\n",
       "      <td>18.6904</td>\n",
       "      <td>728.642500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47962</td>\n",
       "      <td>900957</td>\n",
       "      <td>2021</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.472779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.6189</td>\n",
       "      <td>18.7469</td>\n",
       "      <td>728.642500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47963 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Symbol  year  DirectorNumber  IndependentDirectorNumber  \\\n",
       "0           1  2003            14.0                        3.0   \n",
       "1           1  2004            13.0                        5.0   \n",
       "2           1  2005            14.0                        4.0   \n",
       "3           1  2006            13.0                        4.0   \n",
       "4           1  2007            14.0                        4.0   \n",
       "...       ...   ...             ...                        ...   \n",
       "47958  900957  2017             9.0                        3.0   \n",
       "47959  900957  2018             9.0                        3.0   \n",
       "47960  900957  2019             9.0                        3.0   \n",
       "47961  900957  2020            11.0                        5.0   \n",
       "47962  900957  2021             6.0                        2.0   \n",
       "\n",
       "       board_meeting_num  Tenure  nation_rate  legal_rate  personal_rate  \\\n",
       "0                   13.0     3.0     0.064441    0.000000       0.000000   \n",
       "1                   15.0     1.0     0.000882    0.274816       0.000000   \n",
       "2                   10.0     6.0     0.000882    0.274816       0.000000   \n",
       "3                   12.0    18.0     0.000882    0.274816       0.000000   \n",
       "4                   16.0    30.0     0.002017    0.231715       0.000006   \n",
       "...                  ...     ...          ...         ...            ...   \n",
       "47958                7.0    43.0     0.000000    0.472779       0.000000   \n",
       "47959                4.0    55.0     0.000000    0.472779       0.000000   \n",
       "47960                4.0    67.0     0.000000    0.472779       0.000000   \n",
       "47961                5.0    79.0     0.000000    0.472779       0.000000   \n",
       "47962                4.0    91.0     0.000000    0.472779       0.000000   \n",
       "\n",
       "       is_abroad_exist  1st_rate  2nd_10th_rate  AuditQuality  \n",
       "0                  0.0    7.0838        18.9276     59.944286  \n",
       "1                  1.0   17.8898         8.8375     59.944286  \n",
       "2                  1.0   17.8898         9.3922     59.944286  \n",
       "3                  1.0   17.8898        11.8932     59.944286  \n",
       "4                  1.0   16.6963        14.3021   1019.076154  \n",
       "...                ...       ...            ...           ...  \n",
       "47958              0.0   29.6189        18.8200    728.642500  \n",
       "47959              0.0   29.6189        18.4098    728.642500  \n",
       "47960              0.0   29.6189        18.5604    728.642500  \n",
       "47961              0.0   29.6189        18.6904    728.642500  \n",
       "47962              0.0   29.6189        18.7469    728.642500  \n",
       "\n",
       "[47963 rows x 13 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonfin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 管理层讨论与分析数据处理：2001-2021年\n",
    "数据来源于闲鱼，是从中国研究数据服务平台上搞下来的，[人大数字图书馆](https://libproxy.ruc.edu.cn/ermsClient/eresourceInfo.do?rid=121)也有这个数据库的链接，只不过没有开通管理层讨论与分析的权限\\\n",
    "年报文件夹里的其他文件都是当时用来爬年报和解析年报用的，有了管理层讨论与分析文件夹里面的数据，这些文件就用不到了\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取mda原始文件和中文停用词\n",
    "mda = pd.read_excel('../data/年报/管理层讨论与分析/管理层讨论与分析_raw.xlsx')\n",
    "mda = mda.drop(index=[0],axis=0)\n",
    "drop_half_year = []\n",
    "for i in mda.index:\n",
    "    if mda.loc[i,'Anatime'].split('-')[1] == '06':\n",
    "        # 去除半年度的报告\n",
    "        drop_half_year.append(i)\n",
    "mda.drop(index=drop_half_year, axis=0, inplace=True)\n",
    "mda.reset_index(drop=True, inplace=True)\n",
    "\n",
    "stop_words = []\n",
    "# 读取停用词表\n",
    "with open('../data/年报/chineseStopWords.txt','r') as f:\n",
    "    for line in f.readlines():\n",
    "        stop_words.append(line.replace('\\n',''))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去除停用词，数字和字符 (Bert的话可以去除停用词，也可以不去)，但由于篇幅的原因，还是尽量去掉，减轻计算量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本预处理\n",
    "new_BusDA = []\n",
    "for text in mda.BusDA:\n",
    "    t1 = re.sub(r'\\n','',text)\n",
    "    # 1,699,196,509 元 -> 1699196509 元\n",
    "    t2 = re.sub(r',','',t1)\n",
    "    # 去除数字\n",
    "    t3 = re.sub(r'[0-9]+','',t2)\n",
    "    t4 = ''\n",
    "    # 去除停用词\n",
    "    for word in jieba.cut(t3):\n",
    "        if word not in stop_words:\n",
    "            t4 += word\n",
    "            t4 += \" \"\n",
    "    new_BusDA.append(t4)\n",
    "    \n",
    "mda.BusDA = new_BusDA\n",
    "# 要运行 96 分钟\n",
    "# csv 文件太大了，生成了不方便打开\n",
    "mda.to_excel('../data/年报/管理层讨论与分析/mda_no_number.xlsx',encoding='gb18030',index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda = pd.read_excel('../data/年报/管理层讨论与分析/mda_no_number.xlsx', encoding='gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "年度 本行 主营业务 本行 主营业务 经营范围 中国人民银行 批准 各项 商业银行 业务 包括 人民币 外币 存贷款 国际 国内 结算 票据 贴现 外汇 买卖 提供 担保 信用证 服务 提供 保管箱 服务 报告 期内 经营 情况 本行 经营 班子 贯彻落实 董事会 提出 各项 业务 发展 计划 措施 规范 经营 立行 资产 质量 立行 人才 素质 立行 经济效益 立行 经营 方针 领导 组织 全行 员工 紧紧围绕 一手 抓 市场 一手 抓 质量 这两项 中心 工作 团结 进取 努力 开拓 使 本行 日益 激烈 市场竞争 环境 各项 业务 稳步发展 报告 期内 本行 经营 情况 内部 管理 进一步 强化 报告 期内 本行 引入 独立 董事 制度 进一步 完善 公司法人 治理 结构 健全 内控 机制 强化 风险 控制 本行 内部 资源整合 考核 力度 进一步提高 全行 管理水平 工作效率 报告 期末 本行 监管 指标 符合 中国人民银行 资产 规模 持续 报告 期末 本行 总资产 亿元   年初 增加 亿元 增幅 ％ 本外币 贷款 余额 亿元 年初 增加 亿元   增幅 ％ 存款 增长 报告 期末 本行 各项 存款 余额 亿元   年初 增加   亿元 增幅 ％ 本外币 各项 储蓄存款 余额 亿元   年初 增加 亿元 增幅 ％ 资产 质量 改善 报告 期末 逾 呆 口径 计算 本行 不良贷款 余额   亿元 年初 减少 亿元 不良贷款 率为 ％ 年初 ％ 下降 百分点 各项 业务 发展 报告 期内 本行 存 贷款 大幅 增长 业务 快 发展 全年 新增 发卡 万张 国际 结算 量 亿美元 年初 增长 ％ 全年 各类 中间业务 创造 非 利息收入 亿元 税前 利润 有所增加 报告 期内 本行 税前 利润 亿元 年初 增加 亿元 增幅 ％ 机构 拓展 新 进展 报告 期内 本行 新开设 天津 分行 济南 分行 筹备 青岛 分行 贵阳 分行 成都 分行 全年 本行 营业网点 年初   家 增加 年末 家 科技 建设 较大 进展 报告 期内 采用 前置 构架 全行   一本 帐 先进 特征 新一代 综合 客户服务 系统 天津 珠海   重庆 济南 分支机构 按计划 投入 运行 中国人民银行 年末 全国 商业银行 信贷 报表 资料 统计 报告 期末 全国 家 同类 商业银行 本行 各项 存款 占 市场份额 居 第位   增长幅度 居 第位 各项 贷款 占 市场份额 居 第位 增长幅度 居 第位 资产 利润率 居 第位 报告 期内 占 主营业务 收入 ％ 业务 经营 活动 情况 报告 期内 占 本行 主营业务 收入 ％ 业务 利息收入 本行 利息收入 元 利息支出 元 净 利息收入 元 本行 控股公司 参股 经营 情况 业绩 报告 期内 本行 无 新增 控股公司 投资 股权 投资 中国人民银行 本行 控股 子公司 元盛 股权 投资 办理 脱钩 清理 工作 见 会计报表 附注 会计报表 附注 十四 年度 经营 计划 本行 经营 计划 四个 立行 经营 方针 基础 进一步 完善 市场 开拓 体系 风险 控制 体系 支援 保障体系 推进 体制 创新 战略 业务 特色 战略 科技 先导 战略 人才培养 战略 面向 市场 信息 把握 风险 控制 成本 规模 跨越式 增长 质量 高水平 控制 效益 综合性 提高 提升 本行 综合 竞争能力 崭新面貌 应对 WTO   中外 金融业 竞争 着重 做好 工作 整合 全行 资源 加大 营销 力度 加快 产品 服务 创新   不断完善 本行 市场 开拓 体系 确保全 行 各项 业务 快 增长 严格控制 资产 质量 不断完善 风险 控制 体系   消化不良 资产 存量 全行 资产 质量 进一步 好转 开拓 中间业务 拓宽 收益 来源 成本 管理   改善 利润 结构 进一步提高 经济效益 推进 金融 电子化 建设   稳妥 全行 新一代 综合 客户服务 系统 投产 运营 工作 本行 科技 建设 科技 管理工作 提高 一个 新 水平 加快 人事 培训 工作 传统 职能 人力 资源管理 职能   完善 考核 管理体系 进一步 改进 内部 管理 切实 提高 管理效率 水平 加快 全行 机构 网络 建设 完善 本行 全国性 战略 布局 \n"
     ]
    }
   ],
   "source": [
    "for text in mda.BusDA[:]:\n",
    "    print(text)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "中文Bert代码调用，参考[HuggingFace: bert-based-chinese](https://huggingface.co/bert-base-chinese)，[Bert如何解决长文本问题-知乎](https://www.zhihu.com/question/327450789)，[bert训练数据预处理方法](https://blog.csdn.net/weixin_43643246/article/details/104389624)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertModel, AutoTokenizer, AutoModelForMaskedLM, AutoModel\n",
    "configuration = BertConfig()\n",
    "model = BertModel(configuration)\n",
    "configuration = model.config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.24.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-chinese\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'报告 期内 经营 情况 讨论 分析 主营业务 本行 主营业务 经营范围 中国 银行业 监督管理 委员会 批准 各项 商业银行 业务 包括 办理 人民币 存 贷 结算 汇兑 业务 人民币 票据 承兑 贴现 各项 信托 业务 中国 银行业 监督管理 委员会 批准 发行 买卖 人民币 有价证券 外汇 存款 汇款 境内 境外 借款 境内 境外 发行 代理 发行 外币 有价证券 贸易 非贸易 结算 外币 票据 承兑 贴现 外汇 放款 代客 买卖 外汇 外币 有价证券 自营 外汇 买卖 资信 调查 咨询 见证 业务 中国 银行业 监督管理 委员会 批准 业务 本行 国家 全国性 经营 商业银行 本行 战略性 经营 网络 中国 发达 地区 珠江三角洲 环渤海地区 长江三角洲 本行 正 发展 中国 西部 城市 网络 本行 净 利息收入 增长 % 亿元 人民币 得益于 存款 业务 支持 基础 零售 贷款 业务 产出 利息收入 达 亿元 人民币 贷款 票据 贴现 业务 带来 利息收入 本行 利息收入 来源 本行 在结构上 一般性 贷款 业务 调整 一般性 贷款 带来 利息收入 占 总 利息收入 % 本行 资产 混合 配置管理 方针 本行 贴现 余额 下降 % 一般性 贷款 增加 % 零售 贷款 增幅 达 % 信用卡 贷款 款项 房贷 增长 % % 利率 提高 贷款 结构调整 房贷 业务 迅猛 增长 造就 本行 截止 年月日 一般性 贷款 利息收入 增长 % 实施 更为 资金 成本 管理 利息支出 增长 % 亿元 人民币 年度 本行 资产负债 管理 调整 生息 资产负债 结构 提高 高 生息 资产 比例 减少 高 生息 负债 加上 紧密 动态 利差 率 管理 资金运用 管理 生息 资产 利差 率 上年 百分点 % 因素 均 资金运用 效率 提高 本行 净 利息收入 增长 银行业务 贷款 本行 带来 % 贷款 利息收入 本行 供应链 金融 统率 业务 发展 转型 贸易 融资 专业银行 广受 赞誉 本行 借助 国际 先进 贸易 融资 成熟技术 研发 实施 自偿性 贸易 融资 授信 评级 制度 创新 完善 全程 供应链 金融 产品开发 投产 贸易 融资 操作系统 建立 贸易 融资 产品 经理 团队 深化 中外运 中储 中远 物流 中华 商务网 战略伙伴 合作 初步 构建 供应链 金融 — 物流 — 信息流 服务平台 云 铜 一汽 马自达 等家 大型 集团 企业 签署 总 总 业务 合作 协议 强化 关键 流程 服务平台 营销 渠道 持续 供应链 金融 快速 成长 积蓄 能量 信心 本行 业务 规模 效益 供应链 金融 荣获 深圳市 第二届 金融 创新奖 中国 中小企业 协会 中国 银行业 协会 金融时报 联合 评为 最佳 中小企业 融资 方案 欣喜 调整 盈利 资产 结构 中间业务 增长 成本 管理 业务 利差 盈利 能力 增强 零售 银行业务 零售 贷款 本行 带来 % 贷款 利息收入 日均 零售 贷款 增长额 占 日均 贷款 含 贴现 增长额 % 本行 围绕 做好 产品 做强 渠道 做实 基础 大规模 发展 思路 努力 打造 零售 银行业务 平台 推出 一系列 创新 产品 非 交易 转 双周 供 循环 贷 存 抵贷 房贷 新 产品 多期 结构性 理财产品 成功 发行 本行 首张 全国性 双 币种 联名 信用卡 — — 沃尔玛 畅享 卡 创新 营销 模式 拓宽 营销 渠道 充分利用 媒体 资源 实施 广告 + 互动 创新 营销 方式 策划 双周 供 营销 案例 获 中国 杰出 营销 二等奖 中国 艾菲奖 组织 多种 营销 活动 团队 直销 电话 外呼 方式 交叉 销售 推动 零售 业务 快速增长 末 零售 贷款 录得 % 增幅 增长率 全国性 商业银行 排名 零售 贷款 资产 质量 持续 改善 历史 不良贷款 存量 影响 不良率 仍 年初 % 下降 % 发放 零售 贷款 不良率 % 年度 信用卡 卡量 上年 增长 % 信用卡 佣金 收入 录得 % 增幅 不良资产 管理 业务 本行 推进 不良资产 管理 架构 改革 多样化 清收 手段 推动 清收 目标 落实 完善 激励机制 核销 管理 探索 不良资产 风险 定价 改革 不良资产 清收 管理模式 不良资产 清收 成果 本行 清收 总额 亿元 超过 % 现金 方式 收回 审核 本行 核销 亿元 呆账 资金 同业 业务 本行 保证 流动性 前提 引进 创新 一系列 金融市场 产品 投资银行 产品 利用 期限 错配 短期投资 引进 结构性 理财产品 销售 金额 去年同期 增长 倍 推进 同业 信贷 资产 转让 业务 研究 掉期 金融 衍生 业务 本行 拓展 同业 合作 关系 新增 家 金融 合作伙伴 本行 外汇 远期 交易 本外币 交叉 理财 业务 资格 一系列 措施 提高 本行 资金运用 效率 资金 筹措 能力 电子 银行业务 本行 电子 银行业务 长足进步 网上银行 业务 交易 金额 亿元 交易 笔数 万笔 企业 网银 业务 交易 金额 增长 % 交易 笔数 增长 % 网银 业务 交易 金额 增长 % 交易 笔数 增长 % 网上支付 支付 业务 交易 金额 增加 倍 交易 笔数 增加 倍 实收 佣金 增加 倍 地区 分布 华南地区 资产 总额 增长 % 占 全行 增长额 % 贷款 利息收入 录得 % 增幅 拨备 利润 增长 % 占 全行 增长额 % 得益于 非 应计 贷款 下降 资产负债 结构 调整 利差 水平 提高 华东地区 资产 总额 增长 % 占 全行 增长额 % 贷款 利息收入 录得 % 增幅 拨备 利润 增长 % 占 全行 增长额 % 资产 盈利 能力 提高 受益 信贷 资产 结构 调整 贸易 融资 经营 模式 产品种类 行业 规模 四大 突破 推出 双周 供 创业 宝 存 抵贷 循环 贷 创新 贷款 品种 当地 激烈 竞争 环境 推动 收入 增长 华北 东北地区 资产 总额 增长 % 占 全行 增长额 % 贷款 利息收入 增长 强劲 录得 % 增幅 拨备 利润 增长 % 占 全行 增长额 % 得益于 市场份额 扩张 担保 提货 双周 供 循环 贷 新 产品 推出 调整 资产负债 结构 压 西南地区 资产 总额 增长 % 占 全行 增长额 % 贷款 利息收入 增长 强劲 录得 % 增幅 拨备 利润 增长 '"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = mda.BusDA[5]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['年度本行主营业务本行主营业务经营范围中国人民银行批准各项商业银行业务包括人民币外币存贷款国际国内结算票据贴现外汇买卖提供担保信用证服务提供保管箱服务报告期内经营情况本行经营班子贯彻落实董事会提出各项业务发展计划措施规范经营立行资产质量立行人才素质立行经济效益立行经营方针领导组织全行员工紧紧围绕一手抓市场一手抓质量这两项中心工作团结进取努力开拓使本行日益激烈市场竞争环境各项业务稳步发展报告期内本行经营情况内部管理进一步强化报告期内本行引入独立董事制度进一步完善公司法人治理结构健全内控机制强化风险控制本行内部资源整合考核力度进一步提高全行管理水平工作效率报告期末本行监管指标符合中国人民银行资产规模持续报告期末本行总资产亿元年初增加亿元增幅％本外币贷款余额亿元年初增加亿元增幅％存款增长报告期末本行各项存款余额亿元年初增加亿元增幅％本外币各项储蓄存款余额亿元年初增加亿元增幅％资产质量改善报告期末逾呆口径计算本行不良贷款余额亿元年初减少亿元不良贷款率为％年初％下降百分点各项业务发展报告期内本行存贷款大幅增长业务快发展全年新增发卡万张国际结算量亿美元年初增长％全年各类中间业务创造非利息收入亿元税前',\n",
       " '利润有所增加报告期内本行税前利润亿元年初增加亿元增幅％机构拓展新进展报告期内本行新开设天津分行济南分行筹备青岛分行贵阳分行成都分行全年本行营业网点年初家增加年末家科技建设较大进展报告期内采用前置构架全行一本帐先进特征新一代综合客户服务系统天津珠海重庆济南分支机构按计划投入运行中国人民银行年末全国商业银行信贷报表资料统计报告期末全国家同类商业银行本行各项存款占市场份额居第位增长幅度居第位各项贷款占市场份额居第位增长幅度居第位资产利润率居第位报告期内占主营业务收入％业务经营活动情况报告期内占本行主营业务收入％业务利息收入本行利息收入元利息支出元净利息收入元本行控股公司参股经营情况业绩报告期内本行无新增控股公司投资股权投资中国人民银行本行控股子公司元盛股权投资办理脱钩清理工作见会计报表附注会计报表附注十四年度经营计划本行经营计划四个立行经营方针基础进一步完善市场开拓体系风险控制体系支援保障体系推进体制创新战略业务特色战略科技先导战略人才培养战略面向市场信息把握风险控制成本规模跨越式增长质量高水平控制效益综合性提高提升本行综合竞争能力崭新面貌应对WTO中外金融业竞争着重做好工作整合全行资源加大',\n",
       " '营销力度加快产品服务创新不断完善本行市场开拓体系确保全行各项业务快增长严格控制资产质量不断完善风险控制体系消化不良资产存量全行资产质量进一步好转开拓中间业务拓宽收益来源成本管理改善利润结构进一步提高经济效益推进金融电子化建设稳妥全行新一代综合客户服务系统投产运营工作本行科技建设科技管理工作提高一个新水平加快人事培训工作传统职能人力资源管理职能完善考核管理体系进一步改进内部管理切实提高管理效率水平加快全行机构网络建设完善本行全国性战略布局']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_sentence = ''\n",
    "# bert支持的单个最长的文本是512\n",
    "MAX_SUBSEN_LEN = 500\n",
    "\n",
    "inputs = []\n",
    "for s in text.split(' '):\n",
    "    if len(cur_sentence + s) <= MAX_SUBSEN_LEN:\n",
    "        cur_sentence += s\n",
    "    else:\n",
    "        inputs.append(cur_sentence)\n",
    "        cur_sentence = s\n",
    "# 手动加上最后一段\n",
    "inputs.append(cur_sentence)\n",
    "inputs\n",
    "# 两位数字占一个字符，一个汉字占一个字符\n",
    "# 中文单字分隔，英文数字分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "embs = []\n",
    "DEVICE = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "for section in inputs:\n",
    "    encoded_input = tokenizer(section, return_tensors='pt',padding=True).to(DEVICE)\n",
    "    # tokens.append(encoded_input['input_ids'])\n",
    "    output = model(**encoded_input, return_dict=True)\n",
    "    # 提取出每一个句子的 CLS 向量\n",
    "    # print(output.last_hidden_state[:,0,:].shape)\n",
    "    embs.append(output.last_hidden_state[:,0,:].squeeze().tolist())\n",
    "# embs = torch.tensor(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 768])\n"
     ]
    }
   ],
   "source": [
    "embs = torch.tensor(embs)\n",
    "print(embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.3204, -8.3937, -8.3671,  ..., -7.3723, -7.7074, -7.6464],\n",
       "        [-8.3204, -8.3937, -8.3671,  ..., -7.3723, -7.7074, -7.6464]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty = torch.tensor([])\n",
    "torch.concat([empty, pooling_layer(embs.T).T, pooling_layer(embs.T).T], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 21128])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooling_layer = torch.nn.MaxPool1d(kernel_size=embs.shape[0])\n",
    "pooling_layer(embs.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1220])\n"
     ]
    }
   ],
   "source": [
    "# text = ['本行总资产达到82亿元。']\n",
    "# return_tensors: 'tf'-tensorflow, 'pt'-pytorch\n",
    "encoded_input = tokenizer(text, return_tensors='pt',padding=True)\n",
    "encoded_input['input_ids']\n",
    "print(encoded_input['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda = pd.read_excel('../data/年报/管理层讨论与分析/mda_no_number.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda.to_excel('../data/年报/管理层讨论与分析/mda_no_number.xls', encoding='gb18030', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.0493, -9.0590, -8.8648,  ..., -7.4138, -7.1695, -8.6114],\n",
       "        [-8.5336, -8.5681, -8.3390,  ..., -7.4831, -7.0072, -7.9200],\n",
       "        [-8.7777, -8.7546, -8.5135,  ..., -7.3962, -7.1147, -7.7257]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提取出每一个句子的 CLS 向量\n",
    "output.logits[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.7914, -8.8136, -8.6019,  ..., -7.4484, -7.0883, -8.2657]],\n",
       "       grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把文本的不同段通过池化的方法合并\n",
    "pooling_layer = torch.nn.MaxPool1d(kernel_size=2)\n",
    "pooling_layer(output.logits[:,0].T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解决长文本的样例代码，来源于知乎 https://www.zhihu.com/question/327450789\n",
    "class LongTextDataloader(object):\n",
    "    def __init__(self, filename: str, max_sub_sentence_len: int, batch_size: int, \n",
    "                    shuffle=False):\n",
    "        \"\"\"\n",
    "        长文本dataloader，初始化函数。\n",
    "\n",
    "        Args:\n",
    "            filename (str): 数据集文件\n",
    "            max_sub_sentence_len (int): 每个子句最大的长度限制\n",
    "            batch_size (int): 一次返回多少句子\n",
    "            shuffle (bool): 是否打乱数据集\n",
    "        \"\"\"\n",
    "        self.texts, self.labels = self.__read_file(filename)\n",
    "        assert len(self.texts) == len(self.labels), '[ERROR] texts count not equal label count.'\n",
    "        self.start = 0\n",
    "        self.end = len(self.texts)\n",
    "        self.batch_size = batch_size\n",
    "        self.max_sub_sentence_len = max_sub_sentence_len\n",
    "        self.visit_order = [i for i in range(self.end)]\n",
    "        if shuffle:\n",
    "            random.shuffle(self.visit_order)\n",
    "    \n",
    "    def __read_file(self, filename: str) -> tuple:\n",
    "        \"\"\"\n",
    "        将本地数据集读到数据加载器中。\n",
    "\n",
    "        Args:\n",
    "            filename (str): 数据集文件名\n",
    "\n",
    "        Returns:\n",
    "            [tuple] -> 文本列表，标签列表\n",
    "        \"\"\"\n",
    "        texts, labels = [], []\n",
    "        with open(filename, 'r', encoding='utf8') as f:\n",
    "            for line in f.readlines():\n",
    "                label, text = line.strip().split('\\t')\n",
    "                texts.append(text)\n",
    "                labels.append(label)\n",
    "        return texts, labels\n",
    "\n",
    "    def __split_long_text(self, text: str) -> list:\n",
    "        \"\"\"\n",
    "        用于迭代器返回数据样本的时候将长文本切割为若干条。\n",
    "\n",
    "        Args:\n",
    "            text (str): 长文本, e.g. -> \"我爱中国\"\n",
    "        \n",
    "        Returns:\n",
    "            [list] -> [\"我爱\", \"中国\"]（假设self.max_sub_sentence_len = 2）\n",
    "        \"\"\"\n",
    "        sub_texts, start, length = [], 0, len(text)\n",
    "        while start < length:\n",
    "            sub_texts.append(text[start: start + self.max_sub_sentence_len])\n",
    "            start += self.max_sub_sentence_len\n",
    "        return sub_texts\n",
    "    \n",
    "    def __next__(self) -> dict:\n",
    "        \"\"\"\n",
    "        迭代器，每次返回数据集中的一个样本，返回样本前会先将长文本切割为若干个短句子。\n",
    "\n",
    "        Raises:\n",
    "            StopIteration: [description]\n",
    "\n",
    "        Returns:\n",
    "            [dict] -> {\n",
    "                'text': [sub_sentence 1, sub_sentence 2, ...],\n",
    "                'label': 1\n",
    "            }\n",
    "        \"\"\"\n",
    "        if self.start < self.end:\n",
    "            ret = self.start\n",
    "            batch_end = ret + self.batch_size\n",
    "            self.start += self.batch_size\n",
    "            currents = self.visit_order[ret: batch_end]\n",
    "            return {'text': [self.__split_long_text(self.texts[c]) for c in currents], 'label': [int(self.labels[c]) for c in currents]}\n",
    "        else:\n",
    "            self.start = 0\n",
    "            raise StopIteration\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GPT2 Chinese](https://huggingface.co/uer/gpt2-chinese-cluecorpussmall) 也可以做表示学习，但参数可能比 Bert 多。Bert是3亿参数量;而普通的GPT-2是15亿参数量。而 GPT-3没有中文版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at uer/gpt2-chinese-cluecorpussmall were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model, BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('uer/gpt2-chinese-cluecorpussmall')\n",
    "model = GPT2Model.from_pretrained('uer/gpt2-chinese-cluecorpussmall')\n",
    "\n",
    "# text = \"Replace me by any text you'd like.\"\n",
    "text = '本行总资产达到82亿元。'\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "print(encoded_input['input_ids'].shape, output.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 关系数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将上市公司全称和股票代码对应起来:\n",
    "stk_map_name_id = pd.DataFrame(columns=['FullName','Stkcd'],dtype=object)\n",
    "\n",
    "name_id_dict = {}\n",
    "corp_basic_info = pd.read_excel('../data/上市公司基本情况/STK_LISTEDCOINFOANL.xlsx',encoding='gb18030')\n",
    "corp_basic_info.drop([0,1],inplace=True)\n",
    "for i in corp_basic_info.index:\n",
    "    key = corp_basic_info.loc[i,'FullName']\n",
    "    value = corp_basic_info.loc[i,'Symbol']\n",
    "    name_id_dict[key] = value\n",
    "\n",
    "stk_map_name_id.FullName = name_id_dict.keys()\n",
    "stk_map_name_id.Stkcd = name_id_dict.values()\n",
    "# stk_map_name_id.to_csv('../data/stk_fullname.csv',encoding='gb18030',index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 高管关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初步处理\n",
    "gaoguan = pd.read_excel('../data/高管关系/CG_Director_raw.xlsx',encoding='gb18030')\n",
    "gaoguan.drop([0,1],axis=0,inplace=True)\n",
    "\n",
    "# 把D0701b(现职任职开始日期)、D0702b(现职任职结束日期)删掉\n",
    "gaoguan.drop(['D0701b', 'D0702b'], axis=1, inplace=True)\n",
    "gaoguan = gaoguan.reset_index(drop=True)\n",
    "\n",
    "# 修改列名\n",
    "gaoguan.rename(columns={'D0101b': 'manager', 'PersonID':'manager_id', 'D0201b':'position', 'Reptdt': 'interval'},inplace=True)\n",
    "gaoguan.interval = [t.split('-')[0] for t in gaoguan.interval]\n",
    "\n",
    "# gaoguan.csv：所有上市公司，不只是train_test.csv里面的公司\n",
    "gaoguan.to_csv('../data/高管关系/gaoguan.csv',encoding='gb18030',index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成两个字典：repeat_names 和 duel_people_stk_id，在后面的亲属、关联、股东关系中都会用到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114468 12083\n"
     ]
    }
   ],
   "source": [
    "gaoguan = pd.read_csv('../data/高管关系/gaoguan.csv',encoding='gb18030')\n",
    "people_id = {}\n",
    "repeat_names = set()\n",
    "\n",
    "for i in gaoguan.index:\n",
    "    name = gaoguan.loc[i,'manager']\n",
    "    id = gaoguan.loc[i,'manager_id']\n",
    "    if name in people_id.keys():\n",
    "        if id not in people_id[name]:\n",
    "            people_id[name].append(id)\n",
    "            repeat_names.add(name)\n",
    "    else:\n",
    "        people_id[name] = [id]\n",
    "print(len(people_id),len(repeat_names))\n",
    "\n",
    "# 构造一个字典中的字典：name：stk：id，这个字典用于在扫描所有关系中的重名人，在人名后面加上-id\n",
    "duel_people_stk_id = {}\n",
    "for i in gaoguan.index:\n",
    "    name = gaoguan.loc[i,'manager']\n",
    "    stk = gaoguan.loc[i,'Stkcd']\n",
    "    id = gaoguan.loc[i,'manager_id']\n",
    "    if name in repeat_names:\n",
    "        # 人名重复\n",
    "        if name not in duel_people_stk_id:\n",
    "            duel_people_stk_id[name] = {}\n",
    "        #if stk not in people_stk_id[name]:\n",
    "        duel_people_stk_id[name][stk] = id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高管关系人名配对\n",
    "gaoguan = pd.read_csv('../data/高管关系/gaoguan.csv',encoding='gb18030')\n",
    "gaoguan.manager = [name+'-'+str(duel_people_stk_id[name][stk]) if name in repeat_names else name for name, stk in zip(gaoguan.manager, gaoguan.Stkcd)]\n",
    "gaoguan.to_csv('../data/高管关系/gaoguan_no_dup_person.csv',encoding='gb18030',index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 亲属关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3838\n"
     ]
    }
   ],
   "source": [
    "qinshu = pd.read_excel('../data/股权及亲属关系/HLD_Shrrelchain.xlsx',encoding='gb18030')\n",
    "qinshu.drop([0,1],inplace=True)\n",
    "qinshu = qinshu.reset_index(drop=True)\n",
    "print(len(set(qinshu.Stkcd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要用 base 环境跑，用 anaconda3 跑会报错 pandas\n",
    "# 把所有个体人名记下来，在收集股东关系的时候把人名往外扩\n",
    "pattern = r'近*亲属|配偶的*|夫妻|[父母][子女亲]|[堂亲长胞]*[兄弟姐妹]+的*|[叔侄女儿子]+'\n",
    "people = set()\n",
    "qinshu_temp = pd.DataFrame(columns=['person1','person2','interval','detail','related_stk'],dtype=object)\n",
    "qinshu_temp.to_csv('../data/股权及亲属关系/qinshu.csv',encoding='gb18030',index=None)\n",
    "\n",
    "for i in qinshu.index:\n",
    "    reltype = qinshu.loc[i,'S0601a']\n",
    "    detail = qinshu.loc[i,'S0607a']\n",
    "    if reltype==6 and detail is not np.nan:#reltype=6为亲属关系\n",
    "        year = int(qinshu.loc[i,'Reptdt'].split('-')[0])\n",
    "        person1 = qinshu.loc[i,'S0603a']\n",
    "        person2 = qinshu.loc[i,'S0604a']\n",
    "        keyword = re.findall(pattern,detail.replace('女士',''))\n",
    "        if len(keyword)>0:\n",
    "            people.add(person1)\n",
    "            people.add(person2)\n",
    "            qinshu_temp = pd.DataFrame(\n",
    "                        {'person1':person1,\n",
    "                        'person2':person2,\n",
    "                        'interval':year,\n",
    "                        'detail':detail,\n",
    "                        'related_stk': qinshu.loc[i,'Stkcd']},index=[0])\n",
    "                        # json.dumps(keyword,ensure_ascii=False)\n",
    "            qinshu_temp.to_csv('../data/股权及亲属关系/qinshu.csv',encoding='gb18030',mode='a',header=None,index=None)\n",
    "# re.findall(pattern,'潮州合众、潮州市炎城策划咨询有限公司的股东之一李湘娟为王建瑜的兄长的配偶'.replace('女士',''))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "股权及亲属关系文件 里面的股东关系处理起来太麻烦了，不考虑了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 提取股权及亲属关系文件中的股东关系\n",
    "gudong_temp = pd.DataFrame(columns=['holded','holder','interval','detail'],dtype=object)\n",
    "gudong_temp.to_csv('../data/股权及亲属关系/gudong.csv',encoding='gb18030',index=None)\n",
    "\n",
    "# 这里的关联只是关联方关系，并不形成关联交易\n",
    "\n",
    "for i in qinshu.index:\n",
    "    Stkcd = qinshu.loc[i,'Stkcd']\n",
    "    year = int(qinshu.loc[i,'Reptdt'].split('-')[0])\n",
    "    reltype = qinshu.loc[i,'S0601a']\n",
    "    is_holded_stk_gudong = qinshu.loc[i,'S0602a']\n",
    "    person1 = qinshu.loc[i,'S0603a']\n",
    "    person2 = qinshu.loc[i,'S0604a']\n",
    "    if is_holded_stk_gudong==1:\n",
    "        gudong_temp = pd.DataFrame(\n",
    "            {'holded':Stkcd,\n",
    "            'holder':person1,\n",
    "            'interval':year},index=[0])\n",
    "        gudong_temp.to_csv('../data/股权及亲属关系/gudong.csv',encoding='gb18030',mode='a',header=None,index=None)\n",
    "\n",
    "    is_holder_stk_gudong = qinshu.loc[i,'S0605a']\n",
    "    if is_holder_stk_gudong==1:\n",
    "        gudong_temp = pd.DataFrame(\n",
    "            {'holded':Stkcd,\n",
    "            'holder':person2,\n",
    "            'interval':year},index=[0])\n",
    "        gudong_temp.to_csv('../data/股权及亲属关系/gudong.csv',encoding='gb18030',mode='a',header=None,index=None)\n",
    "\n",
    "    if reltype==1: # 持股关系\n",
    "        detail = qinshu.loc[i,'S0607a']\n",
    "        gudong_temp = pd.DataFrame(\n",
    "            {'holded':person1,\n",
    "            'holder':person2,\n",
    "            'interval':year,\n",
    "            'detail':detail},index=[0])\n",
    "        gudong_temp.to_csv('../data/股权及亲属关系/gudong.csv',encoding='gb18030',mode='a',header=None,index=None)\n",
    "    # elif reltype==2: # 关联关系\n",
    "        \n",
    "# 去重\n",
    "gudong_temp = pd.read_csv('../data/股权及亲属关系/gudong.csv',encoding='gb18030')\n",
    "gudong_temp.drop_duplicates(subset=['holded','holder','interval'],keep='first',inplace=True)\n",
    "gudong_temp.to_csv('../data/股权及亲属关系/gudong.csv',encoding='gb18030',index=None)\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "亲戚关系人名配对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 亲戚关系\n",
    "# '李中秋','吉祥','王萍','王玲玲','刘建民','陈小兵','刘畅','李巍','赵晓红','胡颖', 这些亲戚文件中的人在高管关系中是有重复的\n",
    "print(duel_people_stk_id['李中秋'])\n",
    "qinshu = pd.read_csv('../data/股权及亲属关系/qinshu.csv',encoding='gb18030')\n",
    "qinshu.person1 = [name+'-'+str(duel_people_stk_id[name][stk]) if name in repeat_names and stk in duel_people_stk_id[name] else name for name, stk in zip(qinshu.person1, qinshu.related_stk)]\n",
    "qinshu.person2 = [name+'-'+str(duel_people_stk_id[name][stk]) if name in repeat_names and stk in duel_people_stk_id[name] else name for name, stk in zip(qinshu.person2, qinshu.related_stk)]\n",
    "qinshu.to_csv('../data/股权及亲属关系/qinshu_no_dup_person.csv',encoding='gb18030',index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 子公司关系\n",
    "对于公司名字的通用操作：将英文名的公司去重（删除标点、统一为大写、删除空格等），将中文名的公司名字中的半角标点转为全角，将公司全称和股票代码对上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfirm = pd.read_excel('../data/上市公司子公司情况表/FN_Fn061.xlsx',encoding='gb18030')\n",
    "subfirm.drop([0,1], axis=0, inplace=True )\n",
    "subfirm.drop(['FN_Fn06109','FN_Fn06110'], axis=1, inplace=True)\n",
    "subfirm.rename(columns={'EndDate':'interval','FN_Fn06101':'subsidiary'},inplace=True)\n",
    "subfirm.drop_duplicates(subset=['Stkcd','subsidiary','interval'],keep='first',inplace=True)\n",
    "subfirm = subfirm.reset_index(drop=True)\n",
    "\n",
    "subfirm.interval = [int(t.split('-')[0]) for t in subfirm.interval]\n",
    "# 把一些英文公司名字里面的,.和空格删掉\n",
    "subfirm.subsidiary = [re.sub(r'）', ')', re.sub(r'（','(', re.sub(r'[,.，“”\" \\u3000]+','',i))).upper() for i in subfirm.subsidiary]\n",
    "# 把全称和股票代码链接起来\n",
    "subfirm.subsidiary = [name_id_dict[i] if i in name_id_dict else i for i in subfirm.subsidiary]\n",
    "subfirm.to_csv('../data/上市公司子公司情况表/subsidiary_fullname_matched.csv',encoding='gb18030',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 关联交易"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "guanlian_1 = pd.read_excel('../data/关联方交易/RPT_Operation.xlsx',encoding='gb18030')\n",
    "guanlian_2 = pd.read_excel('../data/关联方交易/RPT_Operation1.xlsx',encoding='gb18030')\n",
    "\n",
    "guanlian_1.drop([0,1],inplace=True)\n",
    "guanlian_2.drop([0,1],inplace=True)\n",
    "\n",
    "guanlian = pd.concat([guanlian_1,guanlian_2])\n",
    "guanlian = guanlian.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "guanlian_temp = pd.DataFrame(columns=['seller','buyer','interval','trans_type'],dtype=object)\n",
    "guanlian_temp.to_csv('../data/关联方交易/guanlian.csv',encoding='gb18030',index=None)\n",
    "\n",
    "buy_pattern = r'[支代]付|购|信托产品|接受担保|接受[^A-Za-z0-9]*[劳服业务管理工程]+|承租|拆入|^[^发提]*[接受委托]*[贷借]款'\n",
    "sell_pattern = r'[销出]售|转让|[提供]*担保|[代]*收[取]*|提供[^A-Za-z0-9]*[劳服业务管理工程]+|出租|拆[出借]+|承包|^[^委]*借款|[发放提供][贷借]款'\n",
    "bi_pattern = r'互[相销]|共同'\n",
    "useless_pattern = r'增资|技术服务|租赁|工程收入|资金往来|委托[经营利息]*|资产托管|还款|承销|资产置换|[劳务股权][交易托管]|装修|签署|抵款|抵押'\n",
    "\n",
    "break_point = 0\n",
    "\n",
    "for i in guanlian.index: \n",
    "    if i < break_point:\n",
    "        continue\n",
    "    # 交易日期，不是公告日期\n",
    "    year = int(guanlian.loc[i,'Trddt'].split('-')[0])\n",
    "    \n",
    "    # 交易性质：1-该交易为本公司与关联方之间的交易;2-关联公司之间的交易\n",
    "    trans_nature = guanlian.loc[i,'Trasub']\n",
    "    # 交易方向：1=上市公司处于卖方立场，2=上市公司处于买方立场，3=上市公司处于无法分辨。\n",
    "    trans_direct = guanlian.loc[i,'Direction']\n",
    "    content = guanlian.loc[i,'Content']\n",
    "    trans_type = guanlian.loc[i,'Kind']\n",
    "    Stkcd = int(guanlian.loc[i,'Stkcd'])\n",
    "    guanlian_firm = guanlian.loc[i,'Repart'].split(',')\n",
    "\n",
    "    if trans_nature==1:\n",
    "        if trans_direct == 1:\n",
    "            seller,buyer = Stkcd, guanlian_firm[0]\n",
    "        elif trans_direct==2:\n",
    "            seller,buyer = guanlian_firm[0], Stkcd\n",
    "        else: # trans_direct=3 多为共同执行\n",
    "            seller,buyer = guanlian_firm[0], Stkcd\n",
    "\n",
    "    elif trans_nature==2:\n",
    "        #print(trans_type)\n",
    "        if len(re.findall(buy_pattern, trans_type))>0:\n",
    "            seller, buyer = guanlian_firm[-1], guanlian_firm[0]\n",
    "        \n",
    "        elif len(re.findall(sell_pattern, trans_type)) > 0:\n",
    "            seller, buyer = guanlian_firm[0],guanlian_firm[-1]\n",
    "        \n",
    "        elif len(re.findall(bi_pattern, trans_type)) > 0: # 双方共同执行\n",
    "            seller, buyer = guanlian_firm[0],guanlian_firm[-1]\n",
    "\n",
    "        elif '供' in trans_type:\n",
    "            try:\n",
    "                firm_position = [content.find(j) for j in guanlian_firm]\n",
    "            except:\n",
    "                continue\n",
    "            if firm_position[0] <= firm_position[-1]:\n",
    "                seller, buyer = guanlian_firm[0],guanlian_firm[-1]\n",
    "            else:\n",
    "                seller, buyer = guanlian_firm[-1],guanlian_firm[0]\n",
    "        elif len(re.findall(useless_pattern, trans_type)) > 0:\n",
    "            continue\n",
    "        else: # 其他pattern太多了，涵盖不完了\n",
    "            continue\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    guanlian_temp = pd.DataFrame({'seller':seller,\n",
    "                'buyer':buyer,\n",
    "                'interval':year,\n",
    "                'trans_type':trans_type},index=[0])\n",
    "    guanlian_temp.to_csv('../data/关联方交易/guanlian.csv',encoding='gb18030',mode='a',header=None,index=None)\n",
    "\n",
    "    del seller, buyer, year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1371739, 4)\n"
     ]
    }
   ],
   "source": [
    "guanlian = pd.read_csv('../data/关联方交易/guanlian.csv',encoding='gb18030')\n",
    "print(guanlian.shape)\n",
    "# 因为构造guanlian.csv时没有去重，所以要在这里去重\n",
    "guanlian.drop_duplicates(subset=['seller','buyer','interval'],keep='last',inplace=True)\n",
    "# guanlian.reset_index(drop=True, inplace=True)\n",
    "guanlian.to_csv('../data/关联方交易/guanlian.csv', encoding='gb18030', index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二轮筛选，排除买/卖方指代不明的关联交易，以及对公司的名字（全角半角、英文名大小写和空格、删除标点）进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(732925, 4)\n"
     ]
    }
   ],
   "source": [
    "guanlian = pd.read_csv('../data/关联方交易/guanlian.csv',encoding='gb18030')\n",
    "print(guanlian.shape)\n",
    "\n",
    "firm_except = r'[高管理]+人员|公司管理层|骨干|成员|员工|关联方|[董|监]事|其他|关联公司|薪酬|副总|[合联营国有关联]+企业|集团内企业|总工程师|总经理|[0-9]*家*[分子项目]+公司|[名个位][自然一致行动发起]+人|[名个位]+股东'\n",
    "drop_list = []\n",
    "useless_name = 'ltd. .ltd inc. limitedsp.zo.o. s.l. llc. s.a. 子公司 limited股东'\n",
    "\n",
    "for i in guanlian.index:\n",
    "    seller = guanlian.loc[i,'seller']\n",
    "    buyer = guanlian.loc[i,'buyer']\n",
    "    if str(seller)=='nan' or str(buyer)=='nan':\n",
    "        drop_list.append(i)\n",
    "        continue\n",
    "\n",
    "    if type(seller)==str:\n",
    "        if '等' in seller and len(re.findall(r'[高中]等|等级',seller)) == 0:\n",
    "            guanlian.loc[i,'seller'] = seller.split('等')[0]\n",
    "        elif '及' in seller:\n",
    "            guanlian.loc[i,'seller'] = seller.split('及')[0]\n",
    "\n",
    "        if len(re.findall(firm_except,seller))>0 or seller.lower() in useless_name:\n",
    "            drop_list.append(i)\n",
    "            continue\n",
    "\n",
    "    if type(buyer)==str:\n",
    "        if '等' in buyer and len(re.findall(r'[高中]等|等级',buyer))== 0:\n",
    "            guanlian.loc[i,'buyer'] = buyer.split('等')[0]\n",
    "        elif '及' in buyer:\n",
    "            guanlian.loc[i,'buyer'] = buyer.split('及')[0]\n",
    "\n",
    "        if len(re.findall(firm_except,buyer))>0 or buyer.lower() in useless_name:\n",
    "            drop_list.append(i)\n",
    "\n",
    "guanlian.drop(drop_list,inplace=True)\n",
    "\n",
    "# 把半角（）替换为()、统一成大写、删除空格和标点\n",
    "guanlian.seller = [re.sub(r'）', ')', re.sub(r'（','(', re.sub(r'[,.，“”\" \\u3000]+','',i))).upper() for i in guanlian.seller]\n",
    "guanlian.buyer = [re.sub(r'）', ')', re.sub(r'（','(', re.sub(r'[,.，“”\" \\u3000]+','',i))).upper() for i in guanlian.buyer]\n",
    "\n",
    "# 再次去重\n",
    "guanlian.drop_duplicates(subset=['seller','buyer','interval'],keep='last',inplace=True)\n",
    "\n",
    "# 把其中的上市公司（全名）转化为股票代码\n",
    "guanlian.seller = [name_id_dict[i] if i in name_id_dict else i for i in guanlian.seller]\n",
    "guanlian.buyer = [name_id_dict[i] if i in name_id_dict else i for i in guanlian.buyer]\n",
    "\n",
    "guanlian.to_csv('../data/关联方交易/guanlian_fullname_matched.csv',encoding='gb18030',index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "人名配对，把重名的人的人名后面加上‘-id’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 关联交易\n",
    "guanlian = pd.read_csv('../data/关联方交易/guanlian_fullname_matched.csv',encoding='gb18030')\n",
    "\n",
    "guanlian_temp = pd.DataFrame(columns=['seller','buyer','interval','trans_type'],dtype=object)\n",
    "guanlian_temp.to_csv('../data/关联方交易/guanlian_no_dup_person.csv',encoding='gb18030',index=None)\n",
    "for i in guanlian.index:\n",
    "    seller, buyer = guanlian.loc[i,'seller'], guanlian.loc[i,'buyer']\n",
    "    if type(buyer)==str and len(buyer)<=4 and buyer in repeat_names:\n",
    "        # 识别 buyer 里面有重名的人名\n",
    "        if re.match(r'[0-9]+',seller) is not None:\n",
    "            seller = int(seller)\n",
    "        elif re.match(r'[0-9]+',guanlian.loc[i+1,'seller']) is not None:\n",
    "            seller = int(guanlian.loc[i+1,'seller'])\n",
    "        elif re.match(r'[0-9]+',guanlian.loc[i-1,'seller']) is not None:\n",
    "            seller = int(guanlian.loc[i-1,'seller'])\n",
    "        elif re.match(r'[0-9]+',guanlian.loc[i+1,'buyer']) is not None:\n",
    "            seller = int(guanlian.loc[i+1,'buyer'])\n",
    "        elif re.match(r'[0-9]+',guanlian.loc[i-1,'buyer']) is not None:\n",
    "            seller = int(guanlian.loc[i-1,'buyer'])\n",
    "\n",
    "        if seller in duel_people_stk_id[buyer]:\n",
    "            buyer = buyer + '-' + str(duel_people_stk_id[buyer][seller])\n",
    "        # 还原seller\n",
    "        seller = guanlian.loc[i,'seller']\n",
    "        \n",
    "    elif type(seller)==str and len(seller)<=4 and seller in repeat_names:\n",
    "        # 识别 seller 里面有重名的人名\n",
    "        if re.match(r'[0-9]+',buyer) is not None:\n",
    "            buyer = int(buyer)\n",
    "        elif re.match(r'[0-9]+',guanlian.loc[i+1,'buyer']) is not None:\n",
    "            buyer = int(guanlian.loc[i+1,'buyer'])\n",
    "        elif re.match(r'[0-9]+',guanlian.loc[i-1,'buyer']) is not None:\n",
    "            buyer = int(guanlian.loc[i-1,'buyer'])\n",
    "        elif re.match(r'[0-9]+',guanlian.loc[i+1,'seller']) is not None:\n",
    "            buyer = int(guanlian.loc[i+1,'seller'])\n",
    "        elif re.match(r'[0-9]+',guanlian.loc[i-1,'seller']) is not None:\n",
    "            buyer = int(guanlian.loc[i-1,'seller'])\n",
    "        # print(seller, buyer, type(buyer), buyer in duel_people_stk_id[seller])\n",
    "        if buyer in duel_people_stk_id[seller]:\n",
    "            seller = seller + '-' + str(duel_people_stk_id[seller][buyer])\n",
    "        buyer = guanlian.loc[i,'buyer']\n",
    "    \n",
    "    guanlian_temp = pd.DataFrame({\n",
    "        'seller': seller,\n",
    "        'buyer': buyer,\n",
    "        'interval': guanlian.loc[i,'interval'],\n",
    "        'trans_type': guanlian.loc[i,'trans_type']}, index=[0])\n",
    "    guanlian_temp.to_csv('../data/关联方交易/guanlian_no_dup_person.csv',encoding='gb18030',index=None, header=None, mode='a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(687121, 4)\n",
      "(686116, 4)\n"
     ]
    }
   ],
   "source": [
    "# 再次去重\n",
    "guanlian = pd.read_csv('../data/关联方交易/guanlian_no_dup_person.csv',encoding='gb18030')\n",
    "print(guanlian.shape)\n",
    "guanlian.drop_duplicates(subset=['seller','buyer','interval'],keep='last',inplace=True)\n",
    "guanlian.to_csv('../data/关联方交易/guanlian_no_dup_person.csv',encoding='gb18030',index=None)\n",
    "print(guanlian.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看关联交易中存在哪些指代性的公司名字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'郝彭',\n",
       " '聂建林',\n",
       " '轴承厂',\n",
       " '梁兴安',\n",
       " '谢乐敏',\n",
       " '简伟文',\n",
       " '诸暨日报社',\n",
       " '中天仕名',\n",
       " '胡颖',\n",
       " '吴越俊',\n",
       " '氯碱发展',\n",
       " '何佳',\n",
       " '杭州安泽',\n",
       " '水泊峡公司',\n",
       " '朱雪松',\n",
       " '罗伶芝',\n",
       " '王小萍',\n",
       " '薛俊东',\n",
       " '蔡穗声',\n",
       " '薛华芬',\n",
       " '兰州环保厂',\n",
       " '周新龙',\n",
       " '李丽萍',\n",
       " '周玉梅',\n",
       " '裘坚樑',\n",
       " '费雨健',\n",
       " '仲玉容',\n",
       " '李素华',\n",
       " '马刚',\n",
       " '黄奕彬',\n",
       " '郭琦',\n",
       " '白建军',\n",
       " '张延',\n",
       " '佛山保恒',\n",
       " '雷伊实业',\n",
       " '高鸣',\n",
       " '刘绍喜',\n",
       " '许俏丹',\n",
       " '韩广德',\n",
       " '包春霞',\n",
       " '李中军',\n",
       " '冯会荣',\n",
       " '来新胜',\n",
       " '青岛广昌',\n",
       " '何启强',\n",
       " '龙功运',\n",
       " '张牧野',\n",
       " '张培德',\n",
       " '曹文法',\n",
       " '张伟泉',\n",
       " '中牧总公司',\n",
       " '龚锦娣',\n",
       " '杨耀光',\n",
       " '盐城邦尼',\n",
       " '胡常建',\n",
       " '何剑锋',\n",
       " '杨琪',\n",
       " '文宇',\n",
       " '蔡再华',\n",
       " '张雁冰',\n",
       " '陈永倬',\n",
       " '陈建鹏',\n",
       " '罗勤',\n",
       " '浙江精工',\n",
       " '乔鲁予',\n",
       " '高志伟先生',\n",
       " '陶国平',\n",
       " '操隆兵',\n",
       " '幸建平',\n",
       " '刘友生',\n",
       " '嘉兴诚鼎宏',\n",
       " '王跃先生',\n",
       " '徐建新',\n",
       " '赵强',\n",
       " '薛亮',\n",
       " '张云升',\n",
       " '西南兵工局',\n",
       " '邱光和',\n",
       " '陈先勇',\n",
       " '孙灵芝',\n",
       " '郑毓庆',\n",
       " '科龙空调',\n",
       " '孙奎发',\n",
       " '李金钟',\n",
       " '郑才刚',\n",
       " '广远公司',\n",
       " '天堂硅谷',\n",
       " '马焰',\n",
       " '李祖芹',\n",
       " '吴毅樑',\n",
       " '中望投资',\n",
       " '韦强',\n",
       " '陆平机器',\n",
       " '长虹日电',\n",
       " '恒大动力',\n",
       " '王青运',\n",
       " '郑有水',\n",
       " '王汉金',\n",
       " '铜陵物流',\n",
       " '广东特玻',\n",
       " '邵夕吾',\n",
       " '姜洪波',\n",
       " '重钢总医院',\n",
       " '栗工',\n",
       " '金敖大',\n",
       " '陈东',\n",
       " '翁小珏',\n",
       " '李建保',\n",
       " '周晓东',\n",
       " '金誉集团',\n",
       " '阳江中心坑',\n",
       " '潘岳燕',\n",
       " '西工厂',\n",
       " '何虎',\n",
       " '潇湘晨报社',\n",
       " '法国公司',\n",
       " '汽销鸿通',\n",
       " '郭英杰',\n",
       " '华黎',\n",
       " '钱木水',\n",
       " '徐伟成',\n",
       " '保利中山',\n",
       " '物业公司',\n",
       " '金雅科技',\n",
       " '陈美杉',\n",
       " '催化公司',\n",
       " 'JWU',\n",
       " '张长胜',\n",
       " '香港华侨城',\n",
       " '北京前景',\n",
       " '吴宗泽',\n",
       " '江汽集团',\n",
       " '成洁',\n",
       " '郑州铁路局',\n",
       " '林荣滨',\n",
       " '尹启祥',\n",
       " '俞有强',\n",
       " '周辉',\n",
       " '坚美华鸿',\n",
       " '荆州沃特玛',\n",
       " '薛俊峰',\n",
       " '郑金都',\n",
       " '胡雪峰',\n",
       " '宁晓',\n",
       " '王国华',\n",
       " '李杰先',\n",
       " '郴州乾嘉盛',\n",
       " '科达视讯',\n",
       " '张清海',\n",
       " '煤制油',\n",
       " '茅宜群',\n",
       " '叶三樟',\n",
       " '华菱连轧',\n",
       " '戴樱',\n",
       " '丁剑平',\n",
       " '肇庆广宇',\n",
       " '赵胜欢',\n",
       " '钟永晖',\n",
       " '杜建军',\n",
       " '吕炜',\n",
       " '王菲',\n",
       " '张继元',\n",
       " '黄贻清',\n",
       " 'LEREE',\n",
       " '杨祉雄',\n",
       " '林伟平',\n",
       " '张灿洪',\n",
       " '黄海兵',\n",
       " '符正平',\n",
       " '吴旭',\n",
       " '张执交',\n",
       " '日月恒',\n",
       " '陈祥兴',\n",
       " '华菱涟钢',\n",
       " '王云富',\n",
       " '西藏力骏',\n",
       " '唐岸莲',\n",
       " '傅海波',\n",
       " '华联SKP',\n",
       " '谷春光',\n",
       " '肖世威',\n",
       " '第三方',\n",
       " '石云爱',\n",
       " '赖德贵',\n",
       " '马哲刚',\n",
       " '姜仁',\n",
       " '李秉详',\n",
       " '刘芳友',\n",
       " '袁先圣',\n",
       " '长春华业',\n",
       " '李春安',\n",
       " '王文学',\n",
       " '包志虎',\n",
       " 'ACT货运',\n",
       " '郑美月',\n",
       " '李中秋',\n",
       " '百川如皋',\n",
       " '靖西电化',\n",
       " '邱嘉臣',\n",
       " '阳煤技校',\n",
       " '袁金钰',\n",
       " '吕勤海',\n",
       " '郗洪浩',\n",
       " '翁伟文',\n",
       " '梁武',\n",
       " '联合卡车',\n",
       " '陈荣根',\n",
       " '刘曙阳',\n",
       " '盾安禾田',\n",
       " '李太杰',\n",
       " '杨晓琳',\n",
       " '嘉兴长茂',\n",
       " '杨怀进',\n",
       " '黄俊辉',\n",
       " '王新国',\n",
       " '蔡建明',\n",
       " '程先锋',\n",
       " '李建锋',\n",
       " '洪子平',\n",
       " '卓润',\n",
       " '郑学根',\n",
       " '中蓝建设局',\n",
       " '李爱启',\n",
       " '汪超涌',\n",
       " '周立军',\n",
       " '李坤奇',\n",
       " '北京首赫',\n",
       " '张鑫淼',\n",
       " '顾维军',\n",
       " '范志全',\n",
       " '邢震声',\n",
       " '佛吉亚部件',\n",
       " '朱碧云',\n",
       " '李凤瑞',\n",
       " '毛景勰',\n",
       " '张轩',\n",
       " '杜俊明',\n",
       " '林金锡',\n",
       " '广州大瀑布',\n",
       " '达利纺织',\n",
       " '刘浩宇',\n",
       " '董监高',\n",
       " '刘勤强',\n",
       " '黄嘉棣',\n",
       " '王明辉',\n",
       " '周泽惠',\n",
       " '梅小明',\n",
       " '邓国昌',\n",
       " '吕仁红',\n",
       " '冯战胜',\n",
       " '范伟荣',\n",
       " '陈庆红',\n",
       " '吴用',\n",
       " '华邦酒店',\n",
       " '吴宗彦',\n",
       " '张世忠',\n",
       " '沈志伟',\n",
       " '宣海东',\n",
       " '孔芸',\n",
       " '朱进康',\n",
       " '登茂通煤业',\n",
       " '郑静',\n",
       " '吴桂冠',\n",
       " '彭政纲',\n",
       " '夏中华',\n",
       " '万安集团',\n",
       " '吕春林',\n",
       " '赵贝贝',\n",
       " '王鹏飞',\n",
       " '袁歆',\n",
       " '周晓卓',\n",
       " '张振新',\n",
       " '西藏麒耀',\n",
       " '彭晓华',\n",
       " '佛山瑞凯明',\n",
       " '吴红平',\n",
       " '陆蓉',\n",
       " '晋禾',\n",
       " '郭芳昀',\n",
       " '周海江',\n",
       " '曹新彤',\n",
       " '夏亮',\n",
       " '华菱集团',\n",
       " '王琰',\n",
       " '谢小英',\n",
       " '黄敬东',\n",
       " '袁向阳',\n",
       " '吴迪',\n",
       " '李显林',\n",
       " '曹克波',\n",
       " '张德生',\n",
       " '杨洁',\n",
       " '陈来鹏',\n",
       " '芜湖运达',\n",
       " '麦国明',\n",
       " '孟繁煜',\n",
       " '承天洋',\n",
       " '方天亮',\n",
       " '拉法基中国',\n",
       " '范超',\n",
       " '齐美胜',\n",
       " '周颖华',\n",
       " '王兰',\n",
       " '尹群',\n",
       " '胡飞鸿',\n",
       " '戴元永',\n",
       " '宫海霞',\n",
       " '曲选辉',\n",
       " '孔飙',\n",
       " '郭兆海',\n",
       " '李松',\n",
       " '天安公司',\n",
       " '航天量子',\n",
       " '王寅',\n",
       " '王泳',\n",
       " '赵锐钧',\n",
       " '苏建国',\n",
       " '楚金甫',\n",
       " '中电下属所',\n",
       " '司贵成',\n",
       " '韩智',\n",
       " '李现秀',\n",
       " '闽东电机厂',\n",
       " '王正江',\n",
       " '张兴明',\n",
       " '于建忠',\n",
       " '江西水箱厂',\n",
       " '赵争鸣',\n",
       " '宝检公司',\n",
       " '永康日报社',\n",
       " '前三名合计',\n",
       " '香港保澳',\n",
       " '肖正连',\n",
       " '章国经',\n",
       " '永达科技',\n",
       " '常静',\n",
       " '吴惠明',\n",
       " '房地产公司',\n",
       " '杨列宁',\n",
       " '宋锡武',\n",
       " '袁隆平',\n",
       " '亮马大厦',\n",
       " '曾胜辉',\n",
       " '贺靖',\n",
       " '沈映斌',\n",
       " '胡季强',\n",
       " '屈明',\n",
       " '齐强',\n",
       " '莱美医药',\n",
       " '银鑫',\n",
       " '徐敏',\n",
       " '富铭置业',\n",
       " '陆沪生',\n",
       " '杨建群',\n",
       " '吴兴荣',\n",
       " '李瑶',\n",
       " '黄伟国',\n",
       " '王义',\n",
       " '邓华堂',\n",
       " '翁洁',\n",
       " '游弋',\n",
       " '唐庆斌',\n",
       " '胡晓珊',\n",
       " '陈美箸',\n",
       " '景兴造纸',\n",
       " '李孝国',\n",
       " '刘铁峰',\n",
       " '叶耀华',\n",
       " '黄泳',\n",
       " '于海红',\n",
       " '滨文公司',\n",
       " '会展集团',\n",
       " '崔付军',\n",
       " '铁姆肯轴承',\n",
       " '俞张立',\n",
       " '宋琪',\n",
       " '冯活晓',\n",
       " '邹作涛',\n",
       " '余荣琳',\n",
       " '王荣安',\n",
       " '蒲白矿务局',\n",
       " '汪静莉',\n",
       " '科信电子',\n",
       " '万士文',\n",
       " '陈义生',\n",
       " '张子刚',\n",
       " '李西民',\n",
       " '张国君',\n",
       " '普洛医药',\n",
       " '宁波中药厂',\n",
       " '王鹏',\n",
       " '南金侠',\n",
       " '陈志明',\n",
       " '兖矿集团',\n",
       " '陈育鑫',\n",
       " '蒋建平',\n",
       " '候忠',\n",
       " '唐世田',\n",
       " '黄德义',\n",
       " '苏宁集团',\n",
       " '郭向华',\n",
       " '徐兴龙',\n",
       " '吴永忠',\n",
       " '伍小云',\n",
       " '雷万友',\n",
       " '三峡集团',\n",
       " '郭瑞',\n",
       " '刘民',\n",
       " '陈卫东',\n",
       " '俞龙生',\n",
       " '董慧宇',\n",
       " '孔详洲',\n",
       " '熊冬',\n",
       " '欧阳青',\n",
       " '深圳艾科泰',\n",
       " '周文元',\n",
       " '金华先',\n",
       " '朱菊芬',\n",
       " '谭骅',\n",
       " '宋建明',\n",
       " '于洪林',\n",
       " '刘美芹',\n",
       " '王飞',\n",
       " '陈永聪',\n",
       " '李文德',\n",
       " '辽机集团',\n",
       " '东锦江',\n",
       " '刘睿',\n",
       " '柯利明',\n",
       " '傅信娥',\n",
       " '易伟华',\n",
       " '臧娜',\n",
       " '何天毅',\n",
       " '袁进',\n",
       " '东阳光实业',\n",
       " '杜云',\n",
       " '曹礼建',\n",
       " '戴春晓',\n",
       " '李如祥',\n",
       " '五院',\n",
       " '广州电商港',\n",
       " '郭少燕',\n",
       " '钱进',\n",
       " '章培林',\n",
       " '玉宝箐电站',\n",
       " '沈爱瑛',\n",
       " '胡海林',\n",
       " '张靖',\n",
       " '王刚',\n",
       " '孙美姣',\n",
       " '姚惟声',\n",
       " '新燕莎',\n",
       " '红博商贸城',\n",
       " '李金明',\n",
       " '姚立生',\n",
       " '王学军',\n",
       " '陈薪薪',\n",
       " '余魏豹',\n",
       " '刘国平',\n",
       " '赵胜兰',\n",
       " '宁波银行',\n",
       " '张新生',\n",
       " '王洪海',\n",
       " '李松青',\n",
       " '李红京',\n",
       " '高赫',\n",
       " '中山发电厂',\n",
       " '马楠',\n",
       " '阮伟祥',\n",
       " '天华百润',\n",
       " '陈忠娇',\n",
       " '李苏华',\n",
       " '段琳',\n",
       " '杨晖',\n",
       " '胡黎强',\n",
       " '蔡志华',\n",
       " '侯雪',\n",
       " '吴权',\n",
       " '黄宇晖',\n",
       " '饶轩志',\n",
       " '池巧丽',\n",
       " '刘霞',\n",
       " '田欣',\n",
       " '郑元连',\n",
       " '张友铭',\n",
       " '周家海',\n",
       " '黄基鹏',\n",
       " '南瑞宾馆',\n",
       " '石思慧',\n",
       " '曹东',\n",
       " '杨生哲',\n",
       " '沈强',\n",
       " '姚长杰',\n",
       " '西安赛尔',\n",
       " '沈湘平',\n",
       " '欧阳业恒',\n",
       " '建材集团',\n",
       " '新华通讯社',\n",
       " '黄昌华',\n",
       " '李友',\n",
       " '王维法',\n",
       " '杨国涛',\n",
       " '锦江汽车',\n",
       " '周华松',\n",
       " '东莞和成',\n",
       " '城开股份',\n",
       " '王相荣',\n",
       " '金雪泉',\n",
       " '周炜',\n",
       " '朱朝阳',\n",
       " '西电避雷器',\n",
       " '黄青蕊',\n",
       " '云南省政府',\n",
       " '徐笑白',\n",
       " '白华',\n",
       " '厉小彤',\n",
       " '郭照相',\n",
       " '庄灿明',\n",
       " '孙青华',\n",
       " '赖香英',\n",
       " '厉炯慧',\n",
       " '液晶公司',\n",
       " '吴念博',\n",
       " '钟华',\n",
       " '庞磊',\n",
       " '国际煤焦化',\n",
       " '廖宁放',\n",
       " '李红雨',\n",
       " '栗延秋',\n",
       " '深圳华富溢',\n",
       " '翁建华',\n",
       " '钱志达',\n",
       " '兰航机电',\n",
       " '李靖',\n",
       " '龚旭东',\n",
       " '西藏铮尚',\n",
       " '叶澄海',\n",
       " '姜河',\n",
       " '安福房地产',\n",
       " '管秩生',\n",
       " '陈冠宇',\n",
       " '吴群',\n",
       " '吴友明',\n",
       " '侯焕才',\n",
       " '南充药厂',\n",
       " '陈炯',\n",
       " '游忠惠',\n",
       " '东莞投资',\n",
       " '苏玉妹',\n",
       " '吴淡珠',\n",
       " '沙角C电厂',\n",
       " '龚伟斌',\n",
       " '蒋俊丽',\n",
       " '合广公司',\n",
       " '李芳',\n",
       " '广通',\n",
       " '长怡科技',\n",
       " '陈同刚',\n",
       " '茹关筠',\n",
       " '张观福',\n",
       " '张冰',\n",
       " '谢晓博',\n",
       " '徐佳东',\n",
       " '朱明虬',\n",
       " '陈金城',\n",
       " '杜安林',\n",
       " '李荫峰',\n",
       " '邵进华',\n",
       " '莫辰宇',\n",
       " '杨承宏',\n",
       " '共鸣杂志社',\n",
       " '施新华',\n",
       " '林印孙',\n",
       " '林科',\n",
       " '赵子安',\n",
       " '陈宗敏',\n",
       " '丁彦辉',\n",
       " '泰禾投资',\n",
       " '李宗松',\n",
       " '尚剑红',\n",
       " '金杰',\n",
       " '冠捷科技',\n",
       " '陈轩',\n",
       " '刘令安',\n",
       " '谢郁武',\n",
       " '湖南电视台',\n",
       " '庞学铨',\n",
       " '王小康',\n",
       " '林建伟',\n",
       " '王俊民先生',\n",
       " '苏海军',\n",
       " '建设铸锻厂',\n",
       " '王兴国',\n",
       " '朱洪志',\n",
       " '郑锦浩',\n",
       " '建工商贸',\n",
       " '军工企业K',\n",
       " '谢圣军',\n",
       " '欧阳文',\n",
       " '宝鸡饭店',\n",
       " '陈飞霖',\n",
       " '吴永荣',\n",
       " '刘永春',\n",
       " '张彤慧',\n",
       " '陈文韬',\n",
       " '聂腾云',\n",
       " '嵇作法',\n",
       " '陈学方',\n",
       " '苏康',\n",
       " '雷永志',\n",
       " '施玲群',\n",
       " '国机宁兴',\n",
       " '钢圈',\n",
       " '胡建',\n",
       " '高宗标',\n",
       " '叶秀冬',\n",
       " '叶立春',\n",
       " '王增金',\n",
       " '郭占文',\n",
       " '马喜腾',\n",
       " '大股东',\n",
       " '汪鑫',\n",
       " '陈永霞',\n",
       " '黄卫枝',\n",
       " '沙启林',\n",
       " '朱宁',\n",
       " '计皓',\n",
       " '房梅芬',\n",
       " '柯王俊',\n",
       " '娄阿亚',\n",
       " '吴耀军',\n",
       " '熊钰麟',\n",
       " '廖垚',\n",
       " '信业私募',\n",
       " '何敏波',\n",
       " '陈常海',\n",
       " '李六兵',\n",
       " '陈国平',\n",
       " '周非',\n",
       " '文亮',\n",
       " '海航财务',\n",
       " '倪茂生',\n",
       " '航电建筑',\n",
       " '张国胜',\n",
       " '熊剑',\n",
       " '黄玮',\n",
       " '邓元贵',\n",
       " '刘华',\n",
       " '康记锟',\n",
       " '沈艳芳',\n",
       " '朱岔峡公司',\n",
       " '刘华俊',\n",
       " '杨恒',\n",
       " '段拥政',\n",
       " '瑞安日报社',\n",
       " '任克雷',\n",
       " '庞伟民',\n",
       " '蔡拾贰',\n",
       " '梁喜军',\n",
       " '梅明',\n",
       " '邵惠兵',\n",
       " '钟耳顺',\n",
       " '寿林平',\n",
       " '购房客户',\n",
       " '北京美年',\n",
       " '周林林',\n",
       " '刘良文',\n",
       " '谢红希',\n",
       " '李胤辉',\n",
       " '阮水龙',\n",
       " '吕晓峰',\n",
       " '张誉萨',\n",
       " '刘虎军',\n",
       " '潘兵',\n",
       " '富平云商',\n",
       " '张晔',\n",
       " '周宏峻',\n",
       " '张庭涛',\n",
       " '向朝东',\n",
       " '刘诚',\n",
       " '黎前虎',\n",
       " '刘肇怀',\n",
       " '袁亚非',\n",
       " '锁亚强',\n",
       " '郭元强',\n",
       " '李东辉',\n",
       " '崔琳',\n",
       " '海峡水泥',\n",
       " '孙金国',\n",
       " '年金基金',\n",
       " '姜维利',\n",
       " '王耀',\n",
       " '胡智奇',\n",
       " '小羚羊',\n",
       " '国商林业',\n",
       " '育青科教',\n",
       " '陈再慰',\n",
       " '张和春',\n",
       " '迪贝控股',\n",
       " '陈体引',\n",
       " '吴培培',\n",
       " '吴海燕',\n",
       " '葛勇',\n",
       " '王远立',\n",
       " '齐广田',\n",
       " '荆错',\n",
       " '周德洪',\n",
       " 'CML',\n",
       " '唐灼林',\n",
       " '李桂莲',\n",
       " '国资公司',\n",
       " '蓝星商社',\n",
       " '汪远思',\n",
       " '蒋君燕',\n",
       " '顾金华',\n",
       " '刘小刚',\n",
       " '许华英',\n",
       " '于伟',\n",
       " '沈健生',\n",
       " '蔡小如',\n",
       " '周萍',\n",
       " '周业军',\n",
       " '张庆文',\n",
       " '赵德华',\n",
       " '杨华军',\n",
       " '付国军',\n",
       " '贾清',\n",
       " '曾超懿',\n",
       " '肖志宁',\n",
       " '王成栋',\n",
       " '范仁德',\n",
       " '张广胜',\n",
       " '成都四方',\n",
       " '三九连锁',\n",
       " '李建国',\n",
       " '熊先军',\n",
       " '易门矿务局',\n",
       " '翁林彦',\n",
       " '吴爱军',\n",
       " '袁倪斌',\n",
       " '樊飞',\n",
       " '彭义兴',\n",
       " '柳美珍',\n",
       " '蔡彩丽',\n",
       " '王彦',\n",
       " '吕钢',\n",
       " '张庆华',\n",
       " '福日实业',\n",
       " '郑军',\n",
       " '杨建成',\n",
       " '东辰公司',\n",
       " '孙卫杰',\n",
       " '常永军',\n",
       " '沈小平',\n",
       " '郑燕林',\n",
       " '张翕',\n",
       " '虞方振',\n",
       " '袁开绪',\n",
       " '陈毓沾',\n",
       " '张利忠',\n",
       " '民族饭店',\n",
       " '保利堂悦',\n",
       " '保利梅州',\n",
       " '张喜乐',\n",
       " '王晶翼',\n",
       " '新疆天龙',\n",
       " '孙玉德',\n",
       " '石维国',\n",
       " '林奇',\n",
       " '殷福华',\n",
       " '柯桂华',\n",
       " '叶剑平',\n",
       " '陈俊儒',\n",
       " '石羽',\n",
       " '海竞信息',\n",
       " '曾广胜',\n",
       " '陶建新',\n",
       " '吴俊',\n",
       " '山东海王',\n",
       " '宋长虹',\n",
       " '刘英筠',\n",
       " '朱国锭',\n",
       " '上海城投',\n",
       " '刘萌',\n",
       " '张家口国润',\n",
       " '张平',\n",
       " '杜闽',\n",
       " '尹群开',\n",
       " '陈灵巧',\n",
       " '肖奋',\n",
       " '郑和平',\n",
       " '姚志豪',\n",
       " '王琳琳',\n",
       " '倪明君',\n",
       " '常怡',\n",
       " '郁旭东',\n",
       " '深投控',\n",
       " '张小盟',\n",
       " '福州中维',\n",
       " '黄福胜',\n",
       " '胡建中',\n",
       " '曾胜',\n",
       " '潘丽春',\n",
       " '周旭',\n",
       " '颜海红',\n",
       " '王民雨',\n",
       " '华商传媒',\n",
       " '陈克忠',\n",
       " '李洪义',\n",
       " '赵术英',\n",
       " '宝日汽车板',\n",
       " '南部永生',\n",
       " '韩丹',\n",
       " '复材公司',\n",
       " '王录吉',\n",
       " '包卫刚',\n",
       " '饶中树',\n",
       " '黄光亮',\n",
       " '宋长文',\n",
       " '闫学廷',\n",
       " '姚彩虹',\n",
       " '士兰明芯',\n",
       " '居静',\n",
       " '尹正龙',\n",
       " '第一百货',\n",
       " '马贤明',\n",
       " '陈伟民',\n",
       " '蔡永太',\n",
       " '胡源湘',\n",
       " '张琼',\n",
       " '建工大厦',\n",
       " '深圳进出口',\n",
       " '郭东泽',\n",
       " '窦勇',\n",
       " '鞍蒂公司',\n",
       " '左辉',\n",
       " '马纲',\n",
       " '刘三显',\n",
       " '保利珠海',\n",
       " '黄文乐',\n",
       " '林国富',\n",
       " '朱荣建',\n",
       " '龚卫良',\n",
       " '胡晓棣',\n",
       " '郑爱民',\n",
       " '宋玉印',\n",
       " '蓝星集团',\n",
       " '杨晓玲',\n",
       " '程凤春',\n",
       " '苏瓷公司',\n",
       " '郭天武',\n",
       " '刘长美',\n",
       " '杨永连',\n",
       " '安凯金达',\n",
       " '范向阳',\n",
       " '李卫东',\n",
       " '王新芳',\n",
       " '李林琳',\n",
       " '黄俞',\n",
       " '徐工重型',\n",
       " '胡卫红',\n",
       " '罗成龙',\n",
       " '李凌志',\n",
       " '颜廷辉',\n",
       " '涂慧芬',\n",
       " '张美芬',\n",
       " '汪乐宇',\n",
       " '高延虎',\n",
       " '吴锡盾',\n",
       " '孙庚文',\n",
       " '李安民',\n",
       " '佟杰',\n",
       " '狄峡',\n",
       " '冯立',\n",
       " '辛显坤',\n",
       " '张九利',\n",
       " '大龙总公司',\n",
       " '张栋梁',\n",
       " '吴亮',\n",
       " '王建平',\n",
       " '朱蓉娟',\n",
       " '王燕清',\n",
       " '聂璐璐',\n",
       " '郝巧灵',\n",
       " '新华航空',\n",
       " '刘开发',\n",
       " '徐昕',\n",
       " '王宗华',\n",
       " '赵小凡',\n",
       " '金三角店',\n",
       " '大为焦化',\n",
       " '财鑫担保',\n",
       " '天神',\n",
       " '黄茂如',\n",
       " '通光强能',\n",
       " '顾建国',\n",
       " '首旅广告',\n",
       " '冯国宝',\n",
       " '咸电电炉',\n",
       " '万峰',\n",
       " '汉江药业',\n",
       " '天都房地产',\n",
       " '唐芬',\n",
       " '林秀华',\n",
       " '钱京',\n",
       " '沈少玲',\n",
       " '林萌',\n",
       " '丁蒙君',\n",
       " '赵美光',\n",
       " '苏净',\n",
       " '关锡源',\n",
       " '韩淑香',\n",
       " '周世杰',\n",
       " '钱盘生',\n",
       " '李荣华',\n",
       " '浙商总会',\n",
       " '众合天诚',\n",
       " '金圆控股',\n",
       " '秦赛峰',\n",
       " '孙伯荣',\n",
       " '吴贤良',\n",
       " '陈全根',\n",
       " '华达微',\n",
       " '谢鹏',\n",
       " '徐自力',\n",
       " '王建军',\n",
       " '刘洪',\n",
       " '何建锋',\n",
       " '楼文浪',\n",
       " '谷远祥',\n",
       " '胡林',\n",
       " '王天翔',\n",
       " '鄢玉珍',\n",
       " '吴希振',\n",
       " '孙策',\n",
       " '楚雄冶炼厂',\n",
       " '进出口',\n",
       " '卓红叶',\n",
       " '张桔洲',\n",
       " '蛇口电视台',\n",
       " '张卫红',\n",
       " '袁斌',\n",
       " '卢文霞',\n",
       " '蔡天明',\n",
       " '胡家智',\n",
       " '杨泽军',\n",
       " '三峡新曲阳',\n",
       " '杨曼丽',\n",
       " '晏志清',\n",
       " '曾喜华',\n",
       " 'EXCEL',\n",
       " '高敏',\n",
       " '陈开元',\n",
       " '何寅',\n",
       " '曹骥',\n",
       " '特来电股份',\n",
       " '金地大百汇',\n",
       " '李荣方',\n",
       " '海螺设计院',\n",
       " '殷晓东夫妇',\n",
       " '吕春雷',\n",
       " '孙玉芹',\n",
       " '李小青',\n",
       " '凯恩销售',\n",
       " '陈礼标',\n",
       " '东阳房开',\n",
       " '建材总厂',\n",
       " '黄粤宁',\n",
       " '王洪田',\n",
       " '博方文化',\n",
       " '任涛',\n",
       " '北京科航',\n",
       " '孙建卫',\n",
       " '美都娱乐城',\n",
       " '严家果',\n",
       " '蒲晓平',\n",
       " '付蓉',\n",
       " '吴淼泳',\n",
       " '聂全新',\n",
       " '施祥贵',\n",
       " '方万鹏',\n",
       " '池旭明',\n",
       " '李盈莹',\n",
       " '折生阳',\n",
       " '陈匡志',\n",
       " '高树增',\n",
       " '京御地产',\n",
       " '邵羽南',\n",
       " '时空公司',\n",
       " '杨四化',\n",
       " '罗巨涛',\n",
       " '董静涛',\n",
       " '罗衍记先生',\n",
       " '富利新公司',\n",
       " '王志清',\n",
       " '青岛慧博',\n",
       " '复星高科',\n",
       " '王社平',\n",
       " '三九集团',\n",
       " '赵剑',\n",
       " ...}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guanlian = pd.read_csv('../data/关联方交易/guanlian_fullname_matched.csv',encoding='gb18030')\n",
    "buhege = set()\n",
    "for i in guanlian.index:\n",
    "    seller = guanlian.loc[i,'seller']\n",
    "    buyer = guanlian.loc[i,'buyer']\n",
    "    try:\n",
    "        seller = int(seller)\n",
    "    except:\n",
    "        if len(seller) < 6:\n",
    "            buhege.add(seller)\n",
    "    try:\n",
    "        buyer = int(buyer)\n",
    "    except:\n",
    "        if len(buyer) < 6:\n",
    "            buhege.add(buyer)\n",
    "with open('../data/关联方交易/useless_list.json','w') as f:\n",
    "    json.dump(list(buhege),f,ensure_ascii=False)\n",
    "buhege"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 股东关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1552557, 10)\n"
     ]
    }
   ],
   "source": [
    "shareholder1 = pd.read_excel('../data/十大股东文件/HLD_Shareholders.xlsx',encoding='gb18030')\n",
    "shareholder2 = pd.read_excel('../data/十大股东文件/HLD_Shareholders1.xlsx',encoding='gb18030')\n",
    "# 初步处理\n",
    "shareholder1.drop([0,1],inplace=True)\n",
    "shareholder2.drop([0,1],inplace=True)\n",
    "shareholder = pd.concat([shareholder1,shareholder2])\n",
    "shareholder = shareholder.reset_index(drop=True)\n",
    "print(shareholder.shape)\n",
    "\n",
    "shareholder.Reptdt = [int(i.split('-')[0]) for i in shareholder.Reptdt]\n",
    "shareholder.rename(columns={'Reptdt':'interval','S0301a':'shareholder'},inplace=True)\n",
    "shareholder.drop(['S0304a','S0305a','S0306a','ShareholderNature','UnCriculationShares','CategoryID','Category'], axis=1, inplace=True)\n",
    "# 十大股东是季度的数据，要去重\n",
    "shareholder.drop_duplicates(subset=['Stkcd','shareholder','interval'],keep='last',inplace=True)\n",
    "shareholder.to_csv('../data/十大股东文件/shareholder.csv',encoding='gb18030',index=None)\n",
    "print(shareholder.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理公司名字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(740650, 3)\n",
      "(740645, 3)\n",
      "(699797, 3)\n"
     ]
    }
   ],
   "source": [
    "shareholder = pd.read_csv('../data/十大股东文件/shareholder.csv',encoding='gb18030')\n",
    "print(shareholder.shape)\n",
    "# 把 Ltd. inc. -> Ltd inc、半角替换为全角, \\u3000 是空格\n",
    "shareholder.shareholder = [re.sub(r'）', ')', re.sub(r'（','(', re.sub(r'[,.，“”\" \\u3000]+','',i))).upper() for i in shareholder.shareholder]\n",
    "shareholder.shareholder = [re.sub(r'－', '-', i).split('-')[0] for i in shareholder.shareholder]\n",
    "\n",
    "shareholder.shareholder = [i.split('等')[0] if '等' in i[1:] and len(re.findall(r'[高中]等|等[级权]',i)) == 0 else i for i in shareholder.shareholder]\n",
    "shareholder.shareholder = [i.split('及')[0] if '及' in i[1:] else i for i in shareholder.shareholder] # 及不是第一个字\n",
    "\n",
    "firm_except = r'[高级管理]+人员|骨干|成员|其他|[名个位][自然一致行动发起]+人|[名个位]+股东'\n",
    "shareholder.drop(set([i if len(re.findall(firm_except,shareholder.shareholder[i])) > 0 else -1 for i in shareholder.index]) - set([-1]), axis = 0, inplace = True)\n",
    "\n",
    "shareholder.shareholder = [name_id_dict[i] if i in name_id_dict else i for i in shareholder.shareholder]\n",
    "\n",
    "print(shareholder.shape)\n",
    "shareholder.drop_duplicates(subset=['Stkcd', 'interval', 'shareholder'],keep='first',inplace=True)\n",
    "print(shareholder.shape)\n",
    "\n",
    "shareholder.to_csv('../data/十大股东文件/shareholder_fullname_matched.csv',encoding='gb18030',index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理股东里重名的人名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "shareholder = pd.read_csv('../data/十大股东文件/shareholder_fullname_matched.csv',encoding='gb18030')\n",
    "shareholder.shareholder = [name+'-'+str(duel_people_stk_id[name][stk]) if name in repeat_names and stk in duel_people_stk_id[name] else name for name, stk in zip(shareholder.shareholder, shareholder.Stkcd)]\n",
    "shareholder.to_csv('../data/十大股东文件/gudong_no_dup_person.csv',encoding='gb18030',index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去除金融公司类别的大股东"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(699797, 3)\n",
      "(540138, 3)\n"
     ]
    }
   ],
   "source": [
    "shareholder = pd.read_csv('../data/十大股东文件/gudong_no_dup_person.csv',encoding='gb18030')\n",
    "fin_pattern = r'基金|证券|银行|保险|[中农工建]行|财富|国泰君安|申银万国|国际金融|资管|易方达|资产管理|信托|理财'\n",
    "print(shareholder.shape)\n",
    "shareholder.drop(set([i if len(re.findall(fin_pattern, str(shareholder.shareholder[i]))) > 0 else -1 for i in shareholder.index]) - set([-1]), axis = 0, inplace = True)\n",
    "print(shareholder.shape)\n",
    "shareholder.to_csv('../data/十大股东文件/gudong_not_fin.csv',encoding='gb18030',index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 供应商关系, 暂时不需要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''gongying = pd.read_excel('../data/前五大供应商关系/SC_TopFivePurchaseInfo_raw.xlsx',encoding='gb18030')\n",
    "gongying.drop([0,1],axis=0,inplace=True)\n",
    "gongying = gongying.reset_index(drop=True)\n",
    "# gongying.set_index(['Symbol'],inplace=True)\n",
    "gongying.set_index(['InstitutionName'],inplace=True)\n",
    "print(gongying.shape)\n",
    "\n",
    "# 先去掉一些看不出来公司名字的\n",
    "import encodings\n",
    "rule = r'第*[一二三四五A-Z]*供[应货方商]-*[一二三四五六七八九十a-eA-Z0-9]*|[A-E甲乙丙丁戊]+[有限]*公司|公司[一二三四五0-9]+|合计|第[一二三四五0-9]+[名位]|单位-*[0-9A-Z一二三四五]+|法人[一二三四五]*|客户[一二三四五0-9]*|排名[1-5]*|品牌[0-9A-Z]*|医药商[一二三四五]*|企业[A-Z]+'\n",
    "drop_index = set()\n",
    "for index in set(gongying.index):\n",
    "    if len(re.findall(rule,index))>0:\n",
    "        drop_index.add(index)\n",
    "    elif len(index)==1 and len(re.findall(r'[0-9A-Z甲乙丙丁戊]',index))>0: # 名字就叫 A,B,C...1,2,3,4...\n",
    "        drop_index.add(index)\n",
    "    elif (len(index)>=1 or len(index)<=2) and len(re.findall(r'[A-Z][0-9]',index))>0: #A1,B2\n",
    "        drop_index.add(index)\n",
    "    elif '*' in index or '某公司' in index or '同一控制下' in index: # 曹**, ****技术有限公司\n",
    "        drop_index.add(index)\n",
    "\n",
    "gongying2 = gongying.drop(list(drop_index),axis=0,inplace=False)\n",
    "gongying2.to_csv('前五大供应商关系/SC_TopFivePurchaseInfo.csv',encoding='gb18030')\n",
    "\n",
    "# 生成用于组成KG的txt文件\n",
    "gongying_temp = pd.DataFrame(columns=['Stkcd','gongying_firm','interval'])\n",
    "\n",
    "gongying_temp.to_csv('../data/前五大供应商关系/gongying.csv',encoding='gb18030')\n",
    "\n",
    "gongying2 = pd.read_csv('../data/前五大供应商关系/SC_TopFivePurchaseInfo.csv',encoding='gb18030')\n",
    "for i in gongying2.index:\n",
    "    symbol = gongying2.loc[i,'Symbol']\n",
    "    year = int(gongying2.loc[i,'EndDate'].split('/')[0])\n",
    "    if not gongying2.loc[i,'BusinessSymbol'] is np.nan:\n",
    "        gongying_firm = gongying2.loc[i,'BusinessSymbol'].split(';')[0]\n",
    "    else:\n",
    "        gongying_firm = gongying2.loc[i,'InstitutionName']\n",
    "    gongying_temp = pd.DataFrame(\n",
    "        {'Stkcd':symbol,\n",
    "        'gongying_firm':gongying_firm,\n",
    "        'interval':year},index=[0])\n",
    "    gongying_temp.to_csv('../data/前五大供应商关系/gongying.csv',encoding='gb18030',mode='a',header=None,index=None)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5484b3874f613c56f67dfe76afc9d70e38b4ca66f35bf223fdfd31467824f203"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
